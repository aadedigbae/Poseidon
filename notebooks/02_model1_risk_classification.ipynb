{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e4b649d",
   "metadata": {},
   "source": [
    "Cell 1 — Header, imports, paths, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f263218e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\n",
      "Using thresholds file: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\configs\\thresholds.yml\n",
      "DATA: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\data\n",
      "ART: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\n"
     ]
    }
   ],
   "source": [
    "# 02_model1_risk_classification.ipynb\n",
    "# Goal: Train a calibrated, robust classifier that predicts risk (LOW/MEDIUM/HIGH)\n",
    "# using deployable signals: Temperature, pH, Turbidity_proxy + Virtual DO/NH3.\n",
    "\n",
    "from pathlib import Path\n",
    "import os, json, math, warnings, yaml\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, f1_score,\n",
    "                             average_precision_score, brier_score_loss)\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "\n",
    "import joblib\n",
    "\n",
    "# ---------- Auto-detect POSEIDON root ----------\n",
    "def find_project_root(project_name=\"POSEIDON\"):\n",
    "    cwd = Path.cwd().resolve()\n",
    "     # check current dir and parents for a folder named \"Poseidon\" (case-insensitive)\n",
    "    project_name_l = project_name.lower()\n",
    "    for p in [cwd] + list(cwd.parents):\n",
    "        if p.name.lower() == project_name_l:\n",
    "            return p\n",
    "    # fallback: if running from 'notebooks' use its parent\n",
    "    if cwd.name.lower() == \"notebooks\" and cwd.parent.exists():\n",
    "        return cwd.parent\n",
    "    raise FileNotFoundError(f\"Could not locate project root '{project_name}'. Starting cwd: {cwd}\")\n",
    "\n",
    "    '''\n",
    "    if cwd.name == project_name:\n",
    "        return cwd\n",
    "    if (cwd / project_name).exists():\n",
    "        return cwd / project_name\n",
    "    for parent in [cwd] + list(cwd.parents):\n",
    "        cand = parent / project_name\n",
    "        if cand.exists():\n",
    "            return cand\n",
    "    raise FileNotFoundError(f\"Could not locate project root '{project_name}'. Starting cwd: {cwd}\")\n",
    "    '''\n",
    "\n",
    "ROOT = find_project_root(\"POSEIDON\")\n",
    "\n",
    "# ---------- Standard project folders ----------\n",
    "DATA      = ROOT / \"data\"\n",
    "INTERIM   = DATA / \"interim\"\n",
    "ART       = ROOT / \"artifacts\"\n",
    "MODEL_REG = ART  / \"model_registry\"\n",
    "CVR       = ART  / \"cv_reports\"\n",
    "HOLD      = ART  / \"holdout_reports\"\n",
    "EXPL      = ART  / \"explainability\"\n",
    "CONFIGS   = ROOT / \"configs\"\n",
    "\n",
    "for d in [MODEL_REG, CVR, HOLD, EXPL]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Load thresholds config ----------\n",
    "cfg_path = CONFIGS / \"thresholds.yml\"\n",
    "if not cfg_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing {cfg_path}. Create it (we provided a template earlier) then rerun.\"\n",
    "    )\n",
    "\n",
    "with open(cfg_path, \"r\") as f:\n",
    "    CFG_THRESH = yaml.safe_load(f)\n",
    "\n",
    "MODEL_VERSION = \"model1_risk_classifier_v1\"\n",
    "RANDOM_SEED  = 42\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"Using thresholds file:\", cfg_path)\n",
    "print(\"DATA:\", DATA)\n",
    "print(\"ART:\", ART)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97facf4",
   "metadata": {},
   "source": [
    "Cell 2 — Load cleaned WQD and virtual sensor models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d7cd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for virtual sensors in: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\soft_sensors\n",
      "Files in soft_sensors: ['virtual_do.joblib', 'virtual_models_metrics.json', 'virtual_nh3.joblib']\n",
      "WQD shape: (4300, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>turbidity_cm</th>\n",
       "      <th>do</th>\n",
       "      <th>pH</th>\n",
       "      <th>ammonia</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>turbidity_proxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.448725</td>\n",
       "      <td>10.127148</td>\n",
       "      <td>0.208153</td>\n",
       "      <td>4.751657</td>\n",
       "      <td>0.286054</td>\n",
       "      <td>2</td>\n",
       "      <td>0.098744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.626666</td>\n",
       "      <td>94.015595</td>\n",
       "      <td>11.434463</td>\n",
       "      <td>3.085154</td>\n",
       "      <td>0.096040</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.121842</td>\n",
       "      <td>90.653462</td>\n",
       "      <td>12.430865</td>\n",
       "      <td>9.648515</td>\n",
       "      <td>0.974501</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature  turbidity_cm         do        pH   ammonia  water_quality  \\\n",
       "0    67.448725     10.127148   0.208153  4.751657  0.286054              2   \n",
       "1    64.626666     94.015595  11.434463  3.085154  0.096040              2   \n",
       "2    65.121842     90.653462  12.430865  9.648515  0.974501              2   \n",
       "\n",
       "   turbidity_proxy  \n",
       "0         0.098744  \n",
       "1         0.010637  \n",
       "2         0.011031  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VM DO features: ['temperature', 'pH', 'turbidity_proxy']\n",
      "VM NH3 features: ['temperature', 'pH', 'turbidity_proxy']\n"
     ]
    }
   ],
   "source": [
    "# Load WQD (clean) produced by 00_data_understanding_eda.ipynb\n",
    "wqd_path = INTERIM / \"wqd_clean.csv\"\n",
    "if not wqd_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing {wqd_path}. Run 00_data_understanding_eda.ipynb first.\")\n",
    "wqd = pd.read_csv(wqd_path)\n",
    "\n",
    "# Load virtual sensors produced by 01_soft_sensors_DO_NH3.ipynb\n",
    "soft_dir    = ART / \"soft_sensors\"\n",
    "vm_do_path  = soft_dir / \"virtual_do.joblib\"\n",
    "vm_nh3_path = soft_dir / \"virtual_nh3.joblib\"\n",
    "\n",
    "print(\"Looking for virtual sensors in:\", soft_dir)\n",
    "print(\"Files in soft_sensors:\", [p.name for p in soft_dir.glob('*')])\n",
    "\n",
    "if not (vm_do_path.exists() and vm_nh3_path.exists()):\n",
    "    raise FileNotFoundError(\n",
    "        \"Virtual sensors not found.\\n\"\n",
    "        f\"Expected:\\n  - {vm_do_path}\\n  - {vm_nh3_path}\\n\"\n",
    "        \"→ Run 01_soft_sensors_DO_NH3.ipynb to train & save them.\"\n",
    "    )\n",
    "\n",
    "vm_do  = joblib.load(vm_do_path)   # {\"model\": mdl, \"features\": [...]}\n",
    "vm_nh3 = joblib.load(vm_nh3_path)\n",
    "\n",
    "print(\"WQD shape:\", wqd.shape)\n",
    "display(wqd.head(3))\n",
    "print(\"VM DO features:\", vm_do[\"features\"])\n",
    "print(\"VM NH3 features:\", vm_nh3[\"features\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb44d8",
   "metadata": {},
   "source": [
    "Cell 3 — Build deployable features (Temp, pH, Turbidity_proxy + Virtual DO/NH3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3faa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature snapshot:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>pH</th>\n",
       "      <th>turbidity_proxy</th>\n",
       "      <th>predicted_do</th>\n",
       "      <th>predicted_nh3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.448725</td>\n",
       "      <td>4.751657</td>\n",
       "      <td>0.098744</td>\n",
       "      <td>5.271772</td>\n",
       "      <td>0.286054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.626666</td>\n",
       "      <td>3.085154</td>\n",
       "      <td>0.010637</td>\n",
       "      <td>4.957571</td>\n",
       "      <td>0.432427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.121842</td>\n",
       "      <td>9.648515</td>\n",
       "      <td>0.011031</td>\n",
       "      <td>10.173653</td>\n",
       "      <td>0.796088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.640334</td>\n",
       "      <td>4.819988</td>\n",
       "      <td>15.072963</td>\n",
       "      <td>7.010061</td>\n",
       "      <td>0.475290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.863434</td>\n",
       "      <td>10.244034</td>\n",
       "      <td>0.471882</td>\n",
       "      <td>5.607760</td>\n",
       "      <td>0.444645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature         pH  turbidity_proxy  predicted_do  predicted_nh3\n",
       "0    67.448725   4.751657         0.098744      5.271772       0.286054\n",
       "1    64.626666   3.085154         0.010637      4.957571       0.432427\n",
       "2    65.121842   9.648515         0.011031     10.173653       0.796088\n",
       "3     1.640334   4.819988        15.072963      7.010061       0.475290\n",
       "4    64.863434  10.244034         0.471882      5.607760       0.444645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deploy-time base inputs (your actual field sensors)\n",
    "INPUTS_DEPLOY = [\"temperature\", \"pH\", \"turbidity_proxy\"]\n",
    "\n",
    "# Base matrix\n",
    "X_base = wqd[INPUTS_DEPLOY].copy()\n",
    "\n",
    "# Predict virtual DO/NH3 strictly from deployable inputs\n",
    "Xv = X_base[vm_do[\"features\"]].values  # same for DO and NH3 models\n",
    "feat = X_base.copy()\n",
    "feat[\"predicted_do\"]  = vm_do[\"model\"].predict(Xv)\n",
    "feat[\"predicted_nh3\"] = vm_nh3[\"model\"].predict(Xv)\n",
    "\n",
    "print(\"Feature snapshot:\")\n",
    "display(feat.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38ef35",
   "metadata": {},
   "source": [
    "Risk labels from REAL DO/NH₃ using config policy (no leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3bdef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label balance (proportion):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MEDIUM</th>\n",
       "      <td>0.554884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOW</th>\n",
       "      <td>0.401163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIGH</th>\n",
       "      <td>0.043953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        proportion\n",
       "MEDIUM    0.554884\n",
       "LOW       0.401163\n",
       "HIGH      0.043953"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Risk labeling from REAL DO/NH3 (no circularity). Config-driven.\n",
    "\n",
    "def label_from_config(row, cfg, q_high_turb):\n",
    "    score = 0\n",
    "    LP = cfg[\"label_policy\"][\"scores\"]\n",
    "\n",
    "    # DO (lower is worse)\n",
    "    do_val   = row[\"do\"]\n",
    "    do_crit  = cfg[\"do\"][\"primary\"][\"critical\"]\n",
    "    do_low   = cfg[\"do\"][\"primary\"][\"low\"]\n",
    "    if do_val < do_crit:\n",
    "        score += LP[\"do\"][\"critical\"]\n",
    "    elif do_val < do_low:\n",
    "        score += LP[\"do\"][\"low\"]\n",
    "\n",
    "    # NH3 (higher is worse)\n",
    "    nh3_val  = row[\"ammonia\"]\n",
    "    nh3_high = cfg[\"nh3\"][\"primary\"][\"high\"]\n",
    "    nh3_elev = cfg[\"nh3\"][\"primary\"][\"elevated\"]\n",
    "    if nh3_val > nh3_high:\n",
    "        score += LP[\"nh3\"][\"high\"]\n",
    "    elif nh3_val > nh3_elev:\n",
    "        score += LP[\"nh3\"][\"elevated\"]\n",
    "\n",
    "    # pH comfort band\n",
    "    if (row[\"pH\"] < cfg[\"pH\"][\"lo\"]) or (row[\"pH\"] > cfg[\"pH\"][\"hi\"]):\n",
    "        score += LP[\"pH_out_of_range\"]\n",
    "\n",
    "    # turbidity proxy (relative high)\n",
    "    if row[\"turbidity_proxy\"] > q_high_turb:\n",
    "        score += LP[\"turbidity_high\"]\n",
    "\n",
    "    # temperature stress\n",
    "    if row[\"temperature\"] > cfg[\"temperature\"][\"hi\"]:\n",
    "        score += LP[\"temperature_high\"]\n",
    "\n",
    "    # score -> label mapping (descending by min_score)\n",
    "    for rule in cfg[\"label_policy\"][\"scores_to_labels\"]:\n",
    "        if score >= rule[\"min_score\"]:\n",
    "            return rule[\"label\"]\n",
    "    return \"LOW\"\n",
    "\n",
    "# Compute relative turbidity threshold from WQD\n",
    "q_mark = wqd[\"turbidity_proxy\"].quantile(CFG_THRESH[\"turbidity_proxy\"][\"quantile_high\"])\n",
    "labels = wqd.apply(lambda r: label_from_config(r, CFG_THRESH, q_mark), axis=1)\n",
    "\n",
    "print(\"Label balance (proportion):\")\n",
    "display(labels.value_counts(normalize=True).rename(\"proportion\").to_frame())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73772b4",
   "metadata": {},
   "source": [
    "Cell 5 — Final training frame + stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e42ceff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3440, 5)  Test: (860, 5)\n",
      "Train label proportions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MEDIUM</th>\n",
       "      <td>0.554942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOW</th>\n",
       "      <td>0.401163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIGH</th>\n",
       "      <td>0.043895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train_prop\n",
       "MEDIUM    0.554942\n",
       "LOW       0.401163\n",
       "HIGH      0.043895"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Final features for classification\n",
    "FEAT_COLS = [\"temperature\", \"pH\", \"turbidity_proxy\", \"predicted_do\", \"predicted_nh3\"]\n",
    "X = feat[FEAT_COLS].copy()\n",
    "y = labels.values\n",
    "\n",
    "# Stratified split to preserve class ratios\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n",
    "print(\"Train label proportions:\")\n",
    "display(pd.Series(y_train).value_counts(normalize=True).rename(\"train_prop\").to_frame())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30336a",
   "metadata": {},
   "source": [
    "Cell 6 — Metrics helpers (macro-AP, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ce3689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected classes: ['HIGH' 'LOW' 'MEDIUM']\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(y_train)\n",
    "print(\"Detected classes:\", classes)\n",
    "\n",
    "def macro_ap_score(y_true, proba, class_list):\n",
    "    \"\"\"\n",
    "    Macro-averaged one-vs-rest Average Precision.\n",
    "    y_true: labels (array-like)\n",
    "    proba : shape (n_samples, n_classes) aligned to class_list order\n",
    "    \"\"\"\n",
    "    y_true_series = pd.Series(y_true)\n",
    "    Y = pd.get_dummies(y_true_series).reindex(columns=class_list, fill_value=0).values\n",
    "    return float(average_precision_score(Y, proba, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca88e50",
   "metadata": {},
   "source": [
    "Cell 7 — Candidates (10) + 5-fold CV leaderboard (class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f18c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating logreg_en ...\n",
      "Evaluating linear_svc ...\n",
      "Evaluating svm_rbf ...\n",
      "Evaluating knn ...\n",
      "Evaluating gnb ...\n",
      "Evaluating dtree ...\n",
      "Evaluating rf ...\n",
      "Evaluating extra ...\n",
      "Evaluating gbrt ...\n",
      "Evaluating rf_depth_limited ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_macro_AP</th>\n",
       "      <th>cv_macro_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gbrt</td>\n",
       "      <td>0.840487</td>\n",
       "      <td>0.781469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rf_depth_limited</td>\n",
       "      <td>0.833735</td>\n",
       "      <td>0.775760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.831555</td>\n",
       "      <td>0.776086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dtree</td>\n",
       "      <td>0.739064</td>\n",
       "      <td>0.710825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>extra</td>\n",
       "      <td>0.738843</td>\n",
       "      <td>0.763419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.707375</td>\n",
       "      <td>0.661775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>0.671864</td>\n",
       "      <td>0.644628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear_svc</td>\n",
       "      <td>0.638054</td>\n",
       "      <td>0.664228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg_en</td>\n",
       "      <td>0.631155</td>\n",
       "      <td>0.652501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gnb</td>\n",
       "      <td>0.625902</td>\n",
       "      <td>0.516893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  cv_macro_AP  cv_macro_F1\n",
       "8              gbrt     0.840487     0.781469\n",
       "9  rf_depth_limited     0.833735     0.775760\n",
       "6                rf     0.831555     0.776086\n",
       "5             dtree     0.739064     0.710825\n",
       "7             extra     0.738843     0.763419\n",
       "3               knn     0.707375     0.661775\n",
       "2           svm_rbf     0.671864     0.644628\n",
       "1        linear_svc     0.638054     0.664228\n",
       "0         logreg_en     0.631155     0.652501\n",
       "4               gnb     0.625902     0.516893"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "class_list = list(classes)\n",
    "\n",
    "candidates = {\n",
    "    \"logreg_en\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            max_iter=1000, multi_class=\"multinomial\",\n",
    "            class_weight=\"balanced\", C=1.5, penalty=\"l2\"\n",
    "        ))\n",
    "    ]),\n",
    "\n",
    "    \"linear_svc\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LinearSVC(class_weight=\"balanced\"))\n",
    "    ]),  # no predict_proba -> softmax decision_function\n",
    "\n",
    "    \"svm_rbf\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(kernel=\"rbf\", probability=True,\n",
    "                    class_weight=\"balanced\", C=2.0, gamma=\"scale\"))\n",
    "    ]),\n",
    "\n",
    "    \"knn\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier(n_neighbors=11))\n",
    "    ]),\n",
    "\n",
    "    \"gnb\": GaussianNB(),\n",
    "\n",
    "    \"dtree\": DecisionTreeClassifier(\n",
    "        max_depth=8, class_weight=\"balanced\", random_state=RANDOM_SEED\n",
    "    ),\n",
    "\n",
    "    \"rf\": RandomForestClassifier(\n",
    "        n_estimators=400, max_depth=None, class_weight=\"balanced\",\n",
    "        random_state=RANDOM_SEED, n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"extra\": ExtraTreesClassifier(\n",
    "        n_estimators=500, class_weight=\"balanced\",\n",
    "        random_state=RANDOM_SEED, n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"gbrt\": GradientBoostingClassifier(random_state=RANDOM_SEED),\n",
    "\n",
    "    \"rf_depth_limited\": RandomForestClassifier(\n",
    "        n_estimators=400, max_depth=16, class_weight=\"balanced\",\n",
    "        random_state=RANDOM_SEED, n_jobs=-1\n",
    "    ),\n",
    "}\n",
    "\n",
    "leaderboard = []\n",
    "for name, pipe in candidates.items():\n",
    "    print(f\"Evaluating {name} ...\")\n",
    "\n",
    "    # Probabilities for macro-AP\n",
    "    if name == \"linear_svc\":\n",
    "        dec = cross_val_predict(pipe, X_train, y_train, cv=skf, method=\"decision_function\")\n",
    "        if dec.ndim == 1:  # binary safety\n",
    "            dec = np.vstack([-dec, dec]).T\n",
    "        dec = dec - dec.max(axis=1, keepdims=True)\n",
    "        proba = np.exp(dec)\n",
    "        proba = proba / proba.sum(axis=1, keepdims=True)\n",
    "    else:\n",
    "        proba = cross_val_predict(pipe, X_train, y_train, cv=skf, method=\"predict_proba\")\n",
    "\n",
    "    # CV predictions (labels) for macro-F1\n",
    "    y_pred = cross_val_predict(pipe, X_train, y_train, cv=skf, method=\"predict\")\n",
    "\n",
    "    ap = macro_ap_score(y_train, proba, class_list)\n",
    "    f1 = f1_score(y_train, y_pred, average=\"macro\")\n",
    "\n",
    "    leaderboard.append({\"model\": name, \"cv_macro_AP\": ap, \"cv_macro_F1\": f1})\n",
    "\n",
    "leader_df = pd.DataFrame(leaderboard).sort_values([\"cv_macro_AP\",\"cv_macro_F1\"], ascending=False)\n",
    "display(leader_df)\n",
    "\n",
    "CVR.mkdir(parents=True, exist_ok=True)\n",
    "leader_df.to_csv(CVR / \"model1_cv_leaderboard.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ae496",
   "metadata": {},
   "source": [
    "Cell 8 — Pick best model → fit + calibrate (isotonic) on validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14acff2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top candidate: gbrt\n",
      "Calibrated classes: ['HIGH' 'LOW' 'MEDIUM']\n"
     ]
    }
   ],
   "source": [
    "best_name = leader_df.iloc[0][\"model\"]\n",
    "print(\"Top candidate:\", best_name)\n",
    "\n",
    "base_model = candidates[best_name]\n",
    "\n",
    "# Split train into inner-train/val for calibration\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=RANDOM_SEED, stratify=y_train\n",
    ")\n",
    "\n",
    "# Fit base\n",
    "base_model.fit(X_tr, y_tr)\n",
    "\n",
    "# Calibrate probabilities (isotonic is accurate; sigmoid is a fallback for very small data)\n",
    "calibrated = CalibratedClassifierCV(base_model, method=\"isotonic\", cv=\"prefit\")\n",
    "calibrated.fit(X_val, y_val)\n",
    "\n",
    "print(\"Calibrated classes:\", calibrated.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6885f7",
   "metadata": {},
   "source": [
    "Cell 9 — Threshold tuning (favor HIGH recall while keeping macro-F1 strong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00c73a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating thresholds: {'HIGH': 0.3}\n"
     ]
    }
   ],
   "source": [
    "def find_thresholds_for_high(model, Xv, yv, classes):\n",
    "    proba = model.predict_proba(Xv)\n",
    "    idx = {c:i for i,c in enumerate(classes)}\n",
    "    thresholds = {\"HIGH\": 0.5}\n",
    "\n",
    "    if \"HIGH\" in idx:\n",
    "        high_idx = idx[\"HIGH\"]\n",
    "        best = (0.5, 0.0)  # (thr, macro_f1)\n",
    "        for t in np.linspace(0.30, 0.70, 21):\n",
    "            y_hat = []\n",
    "            for row in proba:\n",
    "                if row[high_idx] >= t:\n",
    "                    y_hat.append(\"HIGH\")\n",
    "                else:\n",
    "                    y_hat.append(classes[np.argmax(row)])\n",
    "            f1 = f1_score(yv, y_hat, average=\"macro\")\n",
    "            if f1 > best[1]:\n",
    "                best = (float(t), float(f1))\n",
    "        thresholds[\"HIGH\"] = best[0]\n",
    "    return thresholds\n",
    "\n",
    "thresholds = find_thresholds_for_high(calibrated, X_val, y_val, calibrated.classes_)\n",
    "print(\"Operating thresholds:\", thresholds)\n",
    "\n",
    "def predict_with_thresholds(model, X, thresholds, classes):\n",
    "    proba = model.predict_proba(X)\n",
    "    idx = {c:i for i,c in enumerate(classes)}\n",
    "    y_hat = []\n",
    "    for row in proba:\n",
    "        if \"HIGH\" in idx and row[idx[\"HIGH\"]] >= thresholds.get(\"HIGH\", 0.5):\n",
    "            y_hat.append(\"HIGH\")\n",
    "        else:\n",
    "            y_hat.append(classes[np.argmax(row)])\n",
    "    return np.array(y_hat), proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb2192",
   "metadata": {},
   "source": [
    "Cell 10 — Holdout evaluation (baseline vs thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654cd0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline Calibrated]\n",
      "Macro-F1: 0.7087\n",
      "Macro-Precision: 0.8818\n",
      "Macro-Recall: 0.6679\n",
      "Macro AP (OvR): 0.7923\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      " [[ 11   0  27]\n",
      " [  0 305  40]\n",
      " [  0  81 396]]\n",
      "\n",
      "[Thresholded for HIGH]\n",
      "Macro-F1: 0.7325\n",
      "Macro-Precision: 0.7828\n",
      "Macro-Recall: 0.7069\n",
      "Macro AP (OvR): 0.7923\n",
      "Confusion Matrix:\n",
      " [[ 16   0  22]\n",
      " [  0 305  40]\n",
      " [  7  81 389]]\n"
     ]
    }
   ],
   "source": [
    "def holdout_report(model, X_te, y_te, classes, title=\"[Baseline]\"):\n",
    "    y_pred = model.predict(X_te)\n",
    "    proba  = model.predict_proba(X_te)\n",
    "\n",
    "    cr = classification_report(y_te, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_te, y_pred, labels=classes)\n",
    "    ap = macro_ap_score(y_te, proba, list(classes))\n",
    "\n",
    "    print(title)\n",
    "    print(\"Macro-F1:\", round(cr[\"macro avg\"][\"f1-score\"], 4))\n",
    "    print(\"Macro-Precision:\", round(cr[\"macro avg\"][\"precision\"], 4))\n",
    "    print(\"Macro-Recall:\", round(cr[\"macro avg\"][\"recall\"], 4))\n",
    "    print(\"Macro AP (OvR):\", round(ap, 4))\n",
    "    print(\"Confusion Matrix (rows=true, cols=pred):\\n\", cm)\n",
    "\n",
    "    return {\"classification_report\": cr, \"confusion_matrix\": cm.tolist(), \"macro_ap\": ap}\n",
    "\n",
    "base_metrics = holdout_report(calibrated, X_test, y_test, calibrated.classes_, title=\"[Baseline Calibrated]\")\n",
    "\n",
    "y_thr, proba_thr = predict_with_thresholds(calibrated, X_test, thresholds, calibrated.classes_)\n",
    "cr_thr = classification_report(y_test, y_thr, output_dict=True)\n",
    "cm_thr = confusion_matrix(y_test, y_thr, labels=calibrated.classes_)\n",
    "ap_thr = macro_ap_score(y_test, proba_thr, list(calibrated.classes_))\n",
    "\n",
    "print(\"\\n[Thresholded for HIGH]\")\n",
    "print(\"Macro-F1:\", round(cr_thr[\"macro avg\"][\"f1-score\"], 4))\n",
    "print(\"Macro-Precision:\", round(cr_thr[\"macro avg\"][\"precision\"], 4))\n",
    "print(\"Macro-Recall:\", round(cr_thr[\"macro avg\"][\"recall\"], 4))\n",
    "print(\"Macro AP (OvR):\", round(ap_thr, 4))\n",
    "print(\"Confusion Matrix:\\n\", cm_thr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f24efcd",
   "metadata": {},
   "source": [
    "Cell 11 — Persist model bundle + reports (versioned, self-describing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b2389fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model1_risk_classifier.joblib\n",
      " - C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\holdout_reports\\model1_holdout_baseline.json\n",
      " - C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\holdout_reports\\model1_holdout_cm_baseline.csv\n",
      " - C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\holdout_reports\\model1_thresholds.json\n"
     ]
    }
   ],
   "source": [
    "bundle = {\n",
    "    \"model\": calibrated,\n",
    "    \"features\": FEAT_COLS,\n",
    "    \"classes\": list(calibrated.classes_),\n",
    "    \"thresholds\": thresholds,\n",
    "    \"version\": MODEL_VERSION,\n",
    "    \"config_used\": str(cfg_path.name),\n",
    "    \"notes\": \"Calibrated (isotonic); thresholds tuned to emphasize HIGH recall.\"\n",
    "}\n",
    "path_model = MODEL_REG / \"model1_risk_classifier.joblib\"\n",
    "joblib.dump(bundle, path_model)\n",
    "\n",
    "# Save reports\n",
    "with open(HOLD / \"model1_holdout_baseline.json\", \"w\") as f:\n",
    "    json.dump(base_metrics, f, indent=2)\n",
    "\n",
    "np.savetxt(HOLD / \"model1_holdout_cm_baseline.csv\",\n",
    "           np.array(base_metrics[\"confusion_matrix\"]), fmt=\"%d\", delimiter=\",\")\n",
    "\n",
    "with open(HOLD / \"model1_thresholds.json\", \"w\") as f:\n",
    "    json.dump({\"thresholds\": thresholds}, f, indent=2)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", path_model)\n",
    "print(\" -\", HOLD / \"model1_holdout_baseline.json\")\n",
    "print(\" -\", HOLD / \"model1_holdout_cm_baseline.csv\")\n",
    "print(\" -\", HOLD / \"model1_thresholds.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27040210",
   "metadata": {},
   "source": [
    "Cell 12 — Quick global importance (if supported) or note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5114f1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global feature importances:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>turbidity_proxy</th>\n",
       "      <td>0.261728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>0.258812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_nh3</th>\n",
       "      <td>0.167507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_do</th>\n",
       "      <td>0.163909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>0.148043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 importance\n",
       "turbidity_proxy    0.261728\n",
       "temperature        0.258812\n",
       "predicted_nh3      0.167507\n",
       "predicted_do       0.163909\n",
       "pH                 0.148043"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def feature_importance(model_or_pipe, feat_names):\n",
    "    # Try to locate a feature_importances_ attribute (Tree-based models)\n",
    "    try:\n",
    "        if hasattr(model_or_pipe, \"feature_importances_\"):\n",
    "            return pd.Series(model_or_pipe.feature_importances_, index=feat_names).sort_values(ascending=False)\n",
    "        # If wrapped by CalibratedClassifierCV, try the base_estimator\n",
    "        if hasattr(model_or_pipe, \"base_estimator\"):\n",
    "            est = model_or_pipe.base_estimator\n",
    "            if hasattr(est, \"feature_importances_\"):\n",
    "                return pd.Series(est.feature_importances_, index=feat_names).sort_values(ascending=False)\n",
    "        if hasattr(model_or_pipe, \"estimator\"):\n",
    "            est = model_or_pipe.estimator\n",
    "            if hasattr(est, \"feature_importances_\"):\n",
    "                return pd.Series(est.feature_importances_, index=feat_names).sort_values(ascending=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "imp = feature_importance(calibrated, FEAT_COLS)\n",
    "if imp is not None:\n",
    "    print(\"Global feature importances:\")\n",
    "    display(imp.to_frame(\"importance\"))\n",
    "    imp.to_csv(EXPL/\"model1_feature_importance.csv\")\n",
    "else:\n",
    "    print(\"Feature importances not available for this classifier. Use SHAP later (05 notebook).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0cd699",
   "metadata": {},
   "source": [
    "Cell 13 — Local sensitivity (quick “why” proxy; SHAP later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bd77442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local sensitivity (increase each feature by ~10% absolute):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>delta</th>\n",
       "      <th>dP_HIGH</th>\n",
       "      <th>dP_MED</th>\n",
       "      <th>dP_LOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>temperature</td>\n",
       "      <td>2.678594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pH</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531605</td>\n",
       "      <td>-0.531605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turbidity_proxy</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>predicted_do</td>\n",
       "      <td>0.414490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010760</td>\n",
       "      <td>0.010760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predicted_nh3</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010760</td>\n",
       "      <td>0.010760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature     delta  dP_HIGH    dP_MED    dP_LOW\n",
       "0      temperature  2.678594      0.0  0.000000  0.000000\n",
       "1               pH  0.809201      0.0  0.531605 -0.531605\n",
       "2  turbidity_proxy  0.001580      0.0  0.000000  0.000000\n",
       "3     predicted_do  0.414490      0.0 -0.010760  0.010760\n",
       "4    predicted_nh3  0.002467      0.0 -0.010760  0.010760"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def local_sensitivity(model, x_row, feat_cols, delta=0.1):\n",
    "    base_proba = model.predict_proba(x_row.values.reshape(1,-1))[0]\n",
    "    rows = []\n",
    "    idx = {c:i for i,c in enumerate(calibrated.classes_)}\n",
    "    for c in feat_cols:\n",
    "        x2 = x_row.copy()\n",
    "        step = delta * (abs(x_row[c]) + 1e-6)  # small relative change\n",
    "        x2[c] = x2[c] + step\n",
    "        p2 = model.predict_proba(x2.values.reshape(1,-1))[0]\n",
    "        rows.append({\n",
    "            \"feature\": c, \"delta\": float(step),\n",
    "            \"dP_HIGH\": float(p2[idx[\"HIGH\"]] - base_proba[idx[\"HIGH\"]]) if \"HIGH\" in idx else 0.0,\n",
    "            \"dP_MED\" : float(p2[idx[\"MEDIUM\"]] - base_proba[idx[\"MEDIUM\"]]) if \"MEDIUM\" in idx else 0.0,\n",
    "            \"dP_LOW\" : float(p2[idx[\"LOW\"]] - base_proba[idx[\"LOW\"]]) if \"LOW\" in idx else 0.0\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"dP_HIGH\", ascending=False)\n",
    "\n",
    "sample_idx = X_test.index[0]\n",
    "sens_df = local_sensitivity(calibrated, X_test.loc[sample_idx], FEAT_COLS, delta=0.1)\n",
    "print(\"Local sensitivity (increase each feature by ~10% absolute):\")\n",
    "display(sens_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
