{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5668c5aa",
   "metadata": {},
   "source": [
    "Cell 1 — Imports, root, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf35c62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\n",
      "Have XGBoost: True\n"
     ]
    }
   ],
   "source": [
    "# 04_model3_forecasting.ipynb\n",
    "# Goal:\n",
    "# Predict future P(HIGH) risk for multiple horizons using 5 parameters with classical models.\n",
    "\n",
    "from pathlib import Path\n",
    "import os, json, math, warnings, yaml\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 4.5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Optional: XGBoost\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAVE_XGB = True\n",
    "except Exception:\n",
    "    HAVE_XGB = False\n",
    "\n",
    "# Root finder\n",
    "def find_project_root(project_name=\"POSEIDON\"):\n",
    "    cwd = Path.cwd().resolve()\n",
    "    project_name_l = project_name.lower()\n",
    "    for p in [cwd] + list(cwd.parents):\n",
    "        if p.name.lower() == project_name_l:\n",
    "            return p\n",
    "    if cwd.name.lower() == \"notebooks\" and cwd.parent.exists():\n",
    "        return cwd.parent\n",
    "    raise FileNotFoundError(f\"Could not locate project root '{project_name}'. Starting cwd: {cwd}\")\n",
    "\n",
    "ROOT = find_project_root(\"Poseidon\")\n",
    "\n",
    "DATA      = ROOT / \"data\"\n",
    "INTERIM   = DATA / \"interim\"\n",
    "ART       = ROOT / \"artifacts\"\n",
    "MODEL_REG = ART  / \"model_registry\"\n",
    "FORECASTS = ART  / \"forecasts\"\n",
    "REPORTS   = ROOT / \"reports\"\n",
    "CONFIGS   = ROOT / \"configs\"\n",
    "\n",
    "for d in [FORECASTS, REPORTS]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"Have XGBoost:\", HAVE_XGB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26facc5",
   "metadata": {},
   "source": [
    "Cell 2 — Load trusted pseudo-labeled Montería & align schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "424750c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trusted dataset shape: (4345, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pH</th>\n",
       "      <th>turbidity_proxy</th>\n",
       "      <th>predicted_do</th>\n",
       "      <th>predicted_nh3</th>\n",
       "      <th>p_high_teacher</th>\n",
       "      <th>weak_p_high</th>\n",
       "      <th>p_high_cal</th>\n",
       "      <th>risk_argmax</th>\n",
       "      <th>risk_blended</th>\n",
       "      <th>conf_score</th>\n",
       "      <th>high_confidence</th>\n",
       "      <th>proba_HIGH</th>\n",
       "      <th>proba_LOW</th>\n",
       "      <th>proba_MEDIUM</th>\n",
       "      <th>keep_for_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>27.598028</td>\n",
       "      <td>7.937212</td>\n",
       "      <td>0.553292</td>\n",
       "      <td>4.170613</td>\n",
       "      <td>0.029451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022465</td>\n",
       "      <td>0.977535</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01 00:30:00</td>\n",
       "      <td>27.217041</td>\n",
       "      <td>7.872365</td>\n",
       "      <td>0.677565</td>\n",
       "      <td>4.170613</td>\n",
       "      <td>0.028561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022465</td>\n",
       "      <td>0.977535</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01 01:00:00</td>\n",
       "      <td>27.688613</td>\n",
       "      <td>7.941378</td>\n",
       "      <td>0.370436</td>\n",
       "      <td>4.170613</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.859461</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022465</td>\n",
       "      <td>0.977535</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-01 01:30:00</td>\n",
       "      <td>28.213818</td>\n",
       "      <td>7.804893</td>\n",
       "      <td>0.534500</td>\n",
       "      <td>4.181165</td>\n",
       "      <td>0.030799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.859461</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022465</td>\n",
       "      <td>0.977535</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-01 02:00:00</td>\n",
       "      <td>27.159508</td>\n",
       "      <td>7.822742</td>\n",
       "      <td>0.612958</td>\n",
       "      <td>4.170613</td>\n",
       "      <td>0.023461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014942</td>\n",
       "      <td>0.985058</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  temperature        pH  turbidity_proxy  predicted_do  \\\n",
       "0 2025-01-01 00:00:00    27.598028  7.937212         0.553292      4.170613   \n",
       "1 2025-01-01 00:30:00    27.217041  7.872365         0.677565      4.170613   \n",
       "2 2025-01-01 01:00:00    27.688613  7.941378         0.370436      4.170613   \n",
       "3 2025-01-01 01:30:00    28.213818  7.804893         0.534500      4.181165   \n",
       "4 2025-01-01 02:00:00    27.159508  7.822742         0.612958      4.170613   \n",
       "\n",
       "   predicted_nh3  p_high_teacher  weak_p_high  p_high_cal risk_argmax  \\\n",
       "0       0.029451             0.0        0.625    0.177528      MEDIUM   \n",
       "1       0.028561             0.0        0.625    0.177528      MEDIUM   \n",
       "2       0.030651             0.0        0.500    0.140539      MEDIUM   \n",
       "3       0.030799             0.0        0.500    0.140539      MEDIUM   \n",
       "4       0.023461             0.0        0.625    0.177528      MEDIUM   \n",
       "\n",
       "  risk_blended  conf_score  high_confidence  proba_HIGH  proba_LOW  \\\n",
       "0          LOW    0.822472            False         0.0   0.022465   \n",
       "1          LOW    0.822472            False         0.0   0.022465   \n",
       "2          LOW    0.859461             True         0.0   0.022465   \n",
       "3          LOW    0.859461             True         0.0   0.022465   \n",
       "4          LOW    0.822472            False         0.0   0.014942   \n",
       "\n",
       "   proba_MEDIUM  keep_for_training  \n",
       "0      0.977535               True  \n",
       "1      0.977535               True  \n",
       "2      0.977535               True  \n",
       "3      0.977535               True  \n",
       "4      0.985058               True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_high_target describe():\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    4.345000e+03\n",
       "mean     1.500000e-01\n",
       "std      1.861985e-02\n",
       "min      7.708816e-07\n",
       "25%      1.405393e-01\n",
       "50%      1.405393e-01\n",
       "75%      1.775280e-01\n",
       "max      4.209612e-01\n",
       "Name: p_high_target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x540 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk label distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "risk_blended\n",
       "LOW       0.999\n",
       "MEDIUM    0.001\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load trusted pseudo-labeled dataset from 03.1\n",
    "p_trust = INTERIM / \"monteria_pseudolabeled_trusted.csv\"\n",
    "if not p_trust.exists():\n",
    "    raise FileNotFoundError(f\"Missing trusted data at {p_trust}. Run 03.1_model2_pseudo_labeling.ipynb first.\")\n",
    "\n",
    "df = pd.read_csv(p_trust, parse_dates=[\"timestamp\"])\n",
    "df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "print(\"Trusted dataset shape:\", df.shape)\n",
    "display(df.head(5))\n",
    "\n",
    "# Required base columns\n",
    "base_required = [\n",
    "    \"timestamp\",\n",
    "    \"temperature\",\"pH\",\"turbidity_proxy\",\n",
    "    \"predicted_do\",\"predicted_nh3\",\n",
    "    \"risk_blended\",\n",
    "    \"p_high_cal\"\n",
    "]\n",
    "missing_base = [c for c in base_required if c not in df.columns]\n",
    "if missing_base:\n",
    "    raise ValueError(f\"Trusted dataset missing base columns: {missing_base}\")\n",
    "\n",
    "risk_col = \"risk_blended\"\n",
    "df[\"p_high_target\"] = df[\"p_high_cal\"].astype(float)\n",
    "\n",
    "print(\"p_high_target describe():\")\n",
    "display(df[\"p_high_target\"].describe())\n",
    "\n",
    "plt.figure()\n",
    "df[\"p_high_target\"].hist(bins=60)\n",
    "plt.title(\"Distribution of p_high_target\")\n",
    "plt.xlabel(\"p_high_target\"); plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Risk label distribution:\")\n",
    "display(df[risk_col].value_counts(normalize=True).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea387466",
   "metadata": {},
   "source": [
    "Cell 3 — Define horizons & sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb35307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizons (steps): {'+1h': 2, '+6h': 12, '+24h': 48, '+3d': 144}\n",
      "Sensors: ['temperature', 'pH', 'turbidity_proxy', 'predicted_do', 'predicted_nh3']\n",
      "Total rows: 4345\n"
     ]
    }
   ],
   "source": [
    "# Approx. 30-minute sampling frequency\n",
    "HORIZONS = {\n",
    "    \"+1h\":  2,\n",
    "    \"+6h\":  12,\n",
    "    \"+24h\": 48,\n",
    "    \"+3d\":  144,\n",
    "}\n",
    "\n",
    "SENSORS = [\"temperature\",\"pH\",\"turbidity_proxy\",\"predicted_do\",\"predicted_nh3\"]\n",
    "\n",
    "print(\"Horizons (steps):\", HORIZONS)\n",
    "print(\"Sensors:\", SENSORS)\n",
    "print(\"Total rows:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef7e13",
   "metadata": {},
   "source": [
    "Cell 4 — Feature engineering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "214e74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTORY_STEPS controls how many past steps we include.\n",
    "# With ~4345 rows, 24 steps (12h window) is fine.\n",
    "HISTORY_STEPS = 24\n",
    "ROLL_WINDOWS  = [4, 12, 24]  # 2h, 6h, 12h windows\n",
    "USE_SLOPE     = True\n",
    "\n",
    "def add_lag_features(df_in, cols, history_steps):\n",
    "    df = df_in.copy()\n",
    "    for c in cols:\n",
    "        for k in range(1, history_steps+1):\n",
    "            df[f\"{c}_lag{k}\"] = df[c].shift(k)\n",
    "    return df\n",
    "\n",
    "def add_rolling_features(df_in, cols, windows):\n",
    "    df = df_in.copy()\n",
    "    for c in cols:\n",
    "        s = df[c].astype(float)\n",
    "        for w in windows:\n",
    "            df[f\"{c}_roll{w}_mean\"] = s.rolling(w).mean()\n",
    "            df[f\"{c}_roll{w}_std\"]  = s.rolling(w).std()\n",
    "            df[f\"{c}_roll{w}_min\"]  = s.rolling(w).min()\n",
    "            df[f\"{c}_roll{w}_max\"]  = s.rolling(w).max()\n",
    "    return df\n",
    "\n",
    "def add_slope_features(df_in, cols, windows):\n",
    "    df = df_in.copy()\n",
    "    for c in cols:\n",
    "        s = df[c].astype(float)\n",
    "        for w in windows:\n",
    "            df[f\"{c}_slope{w}\"] = (s - s.shift(w)) / w\n",
    "    return df\n",
    "\n",
    "def make_features(df_in):\n",
    "    df = df_in.copy()\n",
    "    df = add_lag_features(df, SENSORS, HISTORY_STEPS)\n",
    "    df = add_rolling_features(df, SENSORS, ROLL_WINDOWS)\n",
    "    if USE_SLOPE:\n",
    "        df = add_slope_features(df, SENSORS, ROLL_WINDOWS)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6712e08",
   "metadata": {},
   "source": [
    "Cell 5 — Build wide feature table + horizon targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21837bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in df: 4345\n",
      "HISTORY_STEPS: 24\n",
      "Rows after lag trimming (X_all): 4321\n",
      "Wide feature table shape: (4321, 211)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>p_high_target</th>\n",
       "      <th>y_cont_+1h</th>\n",
       "      <th>y_cont_+6h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01 12:00:00</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>0.140539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-01 12:30:00</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.140539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01 13:00:00</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>0.140539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  p_high_target  y_cont_+1h  y_cont_+6h\n",
       "0 2025-01-01 12:00:00       0.140539    0.177528    0.140539\n",
       "1 2025-01-01 12:30:00       0.140539    0.140539    0.140539\n",
       "2 2025-01-01 13:00:00       0.177528    0.177528    0.140539"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start from base columns\n",
    "base_cols = [\"timestamp\"] + SENSORS + [\"p_high_target\", risk_col]\n",
    "X_all = make_features(df[base_cols])\n",
    "\n",
    "# Add future targets per horizon\n",
    "for hname, step in HORIZONS.items():\n",
    "    X_all[f\"y_cont_{hname}\"] = df[\"p_high_target\"].shift(-step)\n",
    "    X_all[f\"y_cls_{hname}\"]  = df[risk_col].shift(-step)\n",
    "\n",
    "# Drop rows without full lag history\n",
    "X_all = X_all.iloc[HISTORY_STEPS:].reset_index(drop=True)\n",
    "\n",
    "print(\"Rows in df:\", len(df))\n",
    "print(\"HISTORY_STEPS:\", HISTORY_STEPS)\n",
    "print(\"Rows after lag trimming (X_all):\", len(X_all))\n",
    "\n",
    "if len(X_all) < 200:\n",
    "    raise ValueError(\n",
    "        f\"Only {len(X_all)} rows after lag trimming; not enough for robust forecasting.\\n\"\n",
    "        \"This would mean either your dataset is too small or HISTORY_STEPS is too large.\"\n",
    "    )\n",
    "\n",
    "print(\"Wide feature table shape:\", X_all.shape)\n",
    "display(X_all.head(3)[[\"timestamp\",\"p_high_target\",\"y_cont_+1h\",\"y_cont_+6h\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c8e664",
   "metadata": {},
   "source": [
    "Cell 6 — Time-based split (train / val / test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15c7faf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in X_all: 4321\n",
      "Splits (rows): train = 3024 | val = 648 | test = 649\n",
      "Train: 2025-01-01 12:00:00 -> 2025-03-05 11:30:00\n",
      "Val  : 2025-03-05 12:00:00 -> 2025-03-18 23:30:00\n",
      "Test : 2025-03-19 00:00:00 -> 2025-04-01 12:00:00\n"
     ]
    }
   ],
   "source": [
    "n = len(X_all)\n",
    "print(\"Total rows in X_all:\", n)\n",
    "\n",
    "i_tr = int(0.70 * n)\n",
    "i_va = int(0.85 * n)\n",
    "\n",
    "# Ensure non-empty splits\n",
    "i_tr = max(1, min(i_tr, n-2))\n",
    "i_va = max(i_tr + 1, min(i_va, n-1))\n",
    "\n",
    "X_tr = X_all.iloc[:i_tr].copy()\n",
    "X_va = X_all.iloc[i_tr:i_va].copy()\n",
    "X_te = X_all.iloc[i_va:].copy()\n",
    "\n",
    "print(\"Splits (rows): train =\", len(X_tr), \"| val =\", len(X_va), \"| test =\", len(X_te))\n",
    "print(\"Train:\", X_tr[\"timestamp\"].min(), \"->\", X_tr[\"timestamp\"].max())\n",
    "print(\"Val  :\", X_va[\"timestamp\"].min(), \"->\", X_va[\"timestamp\"].max())\n",
    "print(\"Test :\", X_te[\"timestamp\"].min(), \"->\", X_te[\"timestamp\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921dfe9",
   "metadata": {},
   "source": [
    "Cell 7 — Scaling & helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94053a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk label column (excluded): risk_blended\n",
      "Number of candidate feature columns: 201\n",
      "Number of numeric feature columns actually used: 201\n",
      "First 10 feature cols: ['temperature', 'pH', 'turbidity_proxy', 'predicted_do', 'predicted_nh3', 'p_high_target', 'temperature_lag1', 'temperature_lag2', 'temperature_lag3', 'temperature_lag4']\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 — Scaling & helper functions (exclude label + only numeric features)\n",
    "\n",
    "# 1) Define which columns are *not* features\n",
    "target_cols = [f\"y_cont_{h}\" for h in HORIZONS] + [f\"y_cls_{h}\" for h in HORIZONS]\n",
    "\n",
    "non_feature_cols = [\"timestamp\", risk_col] + target_cols\n",
    "\n",
    "# 2) Start from all columns, remove non-feature ones\n",
    "candidate_feature_cols = [c for c in X_all.columns if c not in non_feature_cols]\n",
    "\n",
    "# 3) Keep only numeric columns (defensive — avoids any accidental strings)\n",
    "numeric_cols = list(X_all[candidate_feature_cols].select_dtypes(include=[np.number]).columns)\n",
    "\n",
    "feature_cols = numeric_cols\n",
    "\n",
    "print(\"Risk label column (excluded):\", risk_col)\n",
    "print(\"Number of candidate feature columns:\", len(candidate_feature_cols))\n",
    "print(\"Number of numeric feature columns actually used:\", len(feature_cols))\n",
    "print(\"First 10 feature cols:\", feature_cols[:10])\n",
    "\n",
    "# 4) Fit scaler on TRAIN features only\n",
    "SCALER = StandardScaler()\n",
    "SCALER.fit(X_tr[feature_cols].astype(float))\n",
    "\n",
    "def transform_block(block):\n",
    "    df_block = block.copy()\n",
    "    X = df_block[feature_cols].astype(float)\n",
    "    X_scaled = SCALER.transform(X)\n",
    "    df_block[feature_cols] = X_scaled\n",
    "    return df_block\n",
    "\n",
    "X_tr_s = transform_block(X_tr)\n",
    "X_va_s = transform_block(X_va)\n",
    "X_te_s = transform_block(X_te)\n",
    "\n",
    "# 5) Metrics + plotting helpers\n",
    "def rmse(a, b): \n",
    "    return float(np.sqrt(mean_squared_error(a, b)))\n",
    "\n",
    "def mae(a, b):  \n",
    "    return float(mean_absolute_error(a, b))\n",
    "\n",
    "def plot_pred_vs_true(ts, y_true, y_pred, title):\n",
    "    plt.figure()\n",
    "    plt.plot(ts, y_true, label=\"True\", lw=1.5)\n",
    "    plt.plot(ts, y_pred, label=\"Pred\", lw=1.0)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time\"); plt.ylabel(\"P(HIGH)\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "def plot_residuals_hist(resid, title):\n",
    "    plt.figure()\n",
    "    plt.hist(resid, bins=40)\n",
    "    plt.title(title + \" | Residuals\")\n",
    "    plt.xlabel(\"Error\"); plt.ylabel(\"Count\")\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3ee4b",
   "metadata": {},
   "source": [
    "Cell 8 — NaN diagnostics & clean-block helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a101ada0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN diagnostics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>split</th>\n",
       "      <th>rows</th>\n",
       "      <th>nan_any_rows</th>\n",
       "      <th>nan_in_y</th>\n",
       "      <th>nan_in_X_any</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+1h</td>\n",
       "      <td>train</td>\n",
       "      <td>3024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+1h</td>\n",
       "      <td>val</td>\n",
       "      <td>648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+1h</td>\n",
       "      <td>test</td>\n",
       "      <td>649</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+6h</td>\n",
       "      <td>train</td>\n",
       "      <td>3024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+6h</td>\n",
       "      <td>val</td>\n",
       "      <td>648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>+6h</td>\n",
       "      <td>test</td>\n",
       "      <td>649</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>+24h</td>\n",
       "      <td>train</td>\n",
       "      <td>3024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>+24h</td>\n",
       "      <td>val</td>\n",
       "      <td>648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>+24h</td>\n",
       "      <td>test</td>\n",
       "      <td>649</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>+3d</td>\n",
       "      <td>train</td>\n",
       "      <td>3024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>+3d</td>\n",
       "      <td>val</td>\n",
       "      <td>648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>+3d</td>\n",
       "      <td>test</td>\n",
       "      <td>649</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   horizon  split  rows  nan_any_rows  nan_in_y  nan_in_X_any\n",
       "0      +1h  train  3024             0         0             0\n",
       "1      +1h    val   648             0         0             0\n",
       "2      +1h   test   649             2         2             0\n",
       "3      +6h  train  3024             0         0             0\n",
       "4      +6h    val   648             0         0             0\n",
       "5      +6h   test   649            12        12             0\n",
       "6     +24h  train  3024             0         0             0\n",
       "7     +24h    val   648             0         0             0\n",
       "8     +24h   test   649            48        48             0\n",
       "9      +3d  train  3024             0         0             0\n",
       "10     +3d    val   648             0         0             0\n",
       "11     +3d   test   649           144       144             0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NaN diagnostics: how many rows per split/horizon have missing in X or y?\n",
    "def nan_report_per_horizon(X_tr_s, X_va_s, X_te_s, feature_cols, horizons):\n",
    "    rep = []\n",
    "    for hname, _ in horizons.items():\n",
    "        for split_name, block in [(\"train\", X_tr_s), (\"val\", X_va_s), (\"test\", X_te_s)]:\n",
    "            cols = feature_cols + [f\"y_cont_{hname}\"]\n",
    "            sub  = block[cols]\n",
    "            rep.append({\n",
    "                \"horizon\": hname,\n",
    "                \"split\": split_name,\n",
    "                \"rows\": len(sub),\n",
    "                \"nan_any_rows\": int(sub.isna().any(axis=1).sum()),\n",
    "                \"nan_in_y\": int(sub[f\"y_cont_{hname}\"].isna().sum()),\n",
    "                \"nan_in_X_any\": int(sub[feature_cols].isna().any(axis=1).sum())\n",
    "            })\n",
    "    return pd.DataFrame(rep)\n",
    "\n",
    "nan_df = nan_report_per_horizon(X_tr_s, X_va_s, X_te_s, feature_cols, HORIZONS)\n",
    "print(\"NaN diagnostics:\")\n",
    "display(nan_df)\n",
    "\n",
    "# Helper: build clean blocks for each horizon\n",
    "def build_clean_blocks_for_horizon(X_tr_s, X_va_s, X_te_s, feature_cols, horizon_name):\n",
    "    cols = feature_cols + [f\"y_cont_{horizon_name}\", \"timestamp\"]\n",
    "\n",
    "    def _clean(block):\n",
    "        sub = block[cols].copy()\n",
    "        sub = sub.dropna(subset=feature_cols + [f\"y_cont_{horizon_name}\"])\n",
    "        X = sub[feature_cols].astype(float).values\n",
    "        y = sub[f\"y_cont_{horizon_name}\"].astype(float).values\n",
    "        ts = sub[\"timestamp\"].values\n",
    "        return X, y, ts\n",
    "\n",
    "    Xtr, ytr, ttr = _clean(X_tr_s)\n",
    "    Xva, yva, tva = _clean(X_va_s)\n",
    "    Xte, yte, tte = _clean(X_te_s)\n",
    "\n",
    "    return (Xtr, ytr, ttr), (Xva, yva, tva), (Xte, yte, tte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ec167",
   "metadata": {},
   "source": [
    "Cell 9 — Classical regressors per horizon (with model selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f9aa241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Horizon +1h (2 steps) ===\n",
      "  ridge  | Val RMSE=0.0187\n",
      "  rf     | Val RMSE=0.0196\n",
      "  extra  | Val RMSE=0.0185\n",
      "  gbrt   | Val RMSE=0.0209\n",
      "  knn    | Val RMSE=0.0186\n",
      "  xgb    | Val RMSE=0.0188\n",
      "  -> Winner: extra | Val RMSE: 0.0185\n",
      "\n",
      "=== Horizon +6h (12 steps) ===\n",
      "  ridge  | Val RMSE=0.0185\n",
      "  rf     | Val RMSE=0.0186\n",
      "  extra  | Val RMSE=0.0182\n",
      "  gbrt   | Val RMSE=0.0183\n",
      "  knn    | Val RMSE=0.0188\n",
      "  xgb    | Val RMSE=0.0185\n",
      "  -> Winner: extra | Val RMSE: 0.0182\n",
      "\n",
      "=== Horizon +24h (48 steps) ===\n",
      "  ridge  | Val RMSE=0.0184\n",
      "  rf     | Val RMSE=0.0182\n",
      "  extra  | Val RMSE=0.0181\n",
      "  gbrt   | Val RMSE=0.0184\n",
      "  knn    | Val RMSE=0.0186\n",
      "  xgb    | Val RMSE=0.0186\n",
      "  -> Winner: extra | Val RMSE: 0.0181\n",
      "\n",
      "=== Horizon +3d (144 steps) ===\n",
      "  ridge  | Val RMSE=0.0185\n",
      "  rf     | Val RMSE=0.0180\n",
      "  extra  | Val RMSE=0.0180\n",
      "  gbrt   | Val RMSE=0.0185\n",
      "  knn    | Val RMSE=0.0187\n",
      "  xgb    | Val RMSE=0.0184\n",
      "  -> Winner: extra | Val RMSE: 0.018\n",
      "\n",
      "Classical model summary (validation only):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>winner</th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+1h</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+6h</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.018187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+24h</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.018107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+3d</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.018020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  horizon winner  val_rmse  test_rmse  test_mae model_type\n",
       "0     +1h  extra  0.018467        NaN       NaN  classical\n",
       "1     +6h  extra  0.018187        NaN       NaN  classical\n",
       "2    +24h  extra  0.018107        NaN       NaN  classical\n",
       "3     +3d  extra  0.018020        NaN       NaN  classical"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 9 — Classical regressors per horizon (with proper cloning)\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "REG_CANDIDATES = {\n",
    "    \"ridge\": Ridge(alpha=1.0, random_state=0),\n",
    "    \"rf\":    RandomForestRegressor(n_estimators=300, random_state=0, n_jobs=-1),\n",
    "    \"extra\": ExtraTreesRegressor(n_estimators=400, random_state=0, n_jobs=-1),\n",
    "    \"gbrt\":  GradientBoostingRegressor(random_state=0),\n",
    "    \"knn\":   KNeighborsRegressor(n_neighbors=15, weights=\"distance\"),\n",
    "}\n",
    "if HAVE_XGB:\n",
    "    REG_CANDIDATES[\"xgb\"] = XGBRegressor(\n",
    "        n_estimators=400, max_depth=6, learning_rate=0.05,\n",
    "        subsample=0.9, colsample_bytree=0.9,\n",
    "        random_state=0, tree_method=\"hist\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "results = []\n",
    "\n",
    "for hname, step in HORIZONS.items():\n",
    "    print(f\"\\n=== Horizon {hname} ({step} steps) ===\")\n",
    "\n",
    "    (Xtr, ytr, ttr), (Xva, yva, tva), (Xte, yte, tte) = build_clean_blocks_for_horizon(\n",
    "        X_tr_s, X_va_s, X_te_s, feature_cols, hname\n",
    "    )\n",
    "\n",
    "    min_rows = 100\n",
    "    if len(Xtr) < min_rows or len(Xva) < 30 or len(Xte) < 30:\n",
    "        print(f\"Too few samples after cleaning for {hname}: \"\n",
    "              f\"train={len(Xtr)}, val={len(Xva)}, test={len(Xte)}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    best_name = None\n",
    "    best_rmse = np.inf\n",
    "\n",
    "    for name, base_est in REG_CANDIDATES.items():\n",
    "        # IMPORTANT: clone the base estimator so we don't overwrite it\n",
    "        mdl = clone(base_est)\n",
    "        mdl.fit(Xtr, ytr)\n",
    "        yva_pred = mdl.predict(Xva)\n",
    "        val_rmse = rmse(yva, yva_pred)\n",
    "        print(f\"  {name:6s} | Val RMSE={val_rmse:.4f}\")\n",
    "        if val_rmse < best_rmse:\n",
    "            best_rmse = val_rmse\n",
    "            best_name = name\n",
    "\n",
    "    print(\"  -> Winner:\", best_name, \"| Val RMSE:\", round(best_rmse,4))\n",
    "\n",
    "    results.append({\n",
    "        \"horizon\": hname,\n",
    "        \"winner\": best_name,\n",
    "        \"val_rmse\": float(best_rmse),\n",
    "        # test metrics will be recomputed in Cell 10\n",
    "        \"test_rmse\": np.nan,\n",
    "        \"test_mae\": np.nan,\n",
    "        \"model_type\": \"classical\",\n",
    "    })\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "print(\"\\nClassical model summary (validation only):\")\n",
    "display(res_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9142c2",
   "metadata": {},
   "source": [
    "Cell 10 — Finalize winners, retrain on train+val, save models + bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ef4bac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final winners by horizon (based on validation RMSE):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>winner</th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+1h</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+24h</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.018107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+3d</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.018020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+6h</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.018187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  horizon winner  val_rmse  test_rmse  test_mae model_type\n",
       "0     +1h  extra  0.018467        NaN       NaN  classical\n",
       "1    +24h  extra  0.018107        NaN       NaN  classical\n",
       "2     +3d  extra  0.018020        NaN       NaN  classical\n",
       "3     +6h  extra  0.018187        NaN       NaN  classical"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Finalizing +1h (extra) ===\n",
      "  Train+Val rows: 3672 | Test rows: 647\n",
      "  Final Test RMSE: 0.0171 | MAE: 0.0145\n",
      "  Saved model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_+1h_extra.joblib\n",
      "\n",
      "=== Finalizing +24h (extra) ===\n",
      "  Train+Val rows: 3672 | Test rows: 601\n",
      "  Final Test RMSE: 0.0169 | MAE: 0.0144\n",
      "  Saved model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_+24h_extra.joblib\n",
      "\n",
      "=== Finalizing +3d (extra) ===\n",
      "  Train+Val rows: 3672 | Test rows: 505\n",
      "  Final Test RMSE: 0.0172 | MAE: 0.0143\n",
      "  Saved model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_+3d_extra.joblib\n",
      "\n",
      "=== Finalizing +6h (extra) ===\n",
      "  Train+Val rows: 3672 | Test rows: 637\n",
      "  Final Test RMSE: 0.0171 | MAE: 0.0146\n",
      "  Saved model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_+6h_extra.joblib\n",
      "\n",
      "Saved forecast bundle: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_forecast_bundle.joblib\n"
     ]
    }
   ],
   "source": [
    "# Cell 10 — Finalize winners, train per horizon on train+val, save models + bundle\n",
    "\n",
    "from sklearn.base import clone\n",
    "import joblib\n",
    "\n",
    "print(\"Final winners by horizon (based on validation RMSE):\")\n",
    "best_by_h = res_df.sort_values([\"horizon\",\"val_rmse\"]).groupby(\"horizon\").head(1).reset_index(drop=True)\n",
    "display(best_by_h)\n",
    "\n",
    "FINAL_MODELS = {}\n",
    "\n",
    "# Helper: build a clean block from a single scaled DataFrame (for train+val or test)\n",
    "def build_clean_single_block(block_s, feature_cols, horizon_name):\n",
    "    cols = feature_cols + [f\"y_cont_{horizon_name}\", \"timestamp\"]\n",
    "    sub = block_s[cols].copy()\n",
    "    sub = sub.dropna(subset=feature_cols + [f\"y_cont_{horizon_name}\"])\n",
    "    X = sub[feature_cols].astype(float).values\n",
    "    y = sub[f\"y_cont_{horizon_name}\"].astype(float).values\n",
    "    ts = sub[\"timestamp\"].values\n",
    "    return X, y, ts\n",
    "\n",
    "for _, row in best_by_h.iterrows():\n",
    "    hname   = row[\"horizon\"]\n",
    "    winname = row[\"winner\"]\n",
    "    print(f\"\\n=== Finalizing {hname} ({winname}) ===\")\n",
    "\n",
    "    # Merge TRAIN + VAL\n",
    "    X_trva_s = pd.concat([X_tr_s, X_va_s], axis=0).reset_index(drop=True)\n",
    "\n",
    "    # Build cleaned blocks\n",
    "    Xtrva, ytrva, ttrva = build_clean_single_block(X_trva_s, feature_cols, hname)\n",
    "    Xte,   yte,   tte   = build_clean_single_block(X_te_s,   feature_cols, hname)\n",
    "\n",
    "    print(\"  Train+Val rows:\", len(Xtrva), \"| Test rows:\", len(Xte))\n",
    "    if len(Xtrva) < 100 or len(Xte) < 30:\n",
    "        print(f\"  WARNING: Few samples for {hname} even after combining train+val. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Clone base estimator and train\n",
    "    base_est = REG_CANDIDATES[winname]\n",
    "    mdl = clone(base_est)\n",
    "    mdl.fit(Xtrva, ytrva)\n",
    "\n",
    "    # Evaluate on test\n",
    "    yte_pred = mdl.predict(Xte)\n",
    "    final_rmse = rmse(yte, yte_pred)\n",
    "    final_mae  = mae(yte, yte_pred)\n",
    "    print(\"  Final Test RMSE:\", round(final_rmse,4), \"| MAE:\", round(final_mae,4))\n",
    "\n",
    "    FINAL_MODELS[hname] = {\n",
    "        \"name\": winname,\n",
    "        \"model\": mdl,\n",
    "        \"test_rmse\": float(final_rmse),\n",
    "        \"test_mae\": float(final_mae),\n",
    "    }\n",
    "\n",
    "    # Save this horizon's model\n",
    "    path = MODEL_REG / f\"model3_{hname}_{winname}.joblib\"\n",
    "    joblib.dump(mdl, path)\n",
    "    print(\"  Saved model:\", path)\n",
    "\n",
    "# Bundle (shared config + per-horizon metrics; models themselves saved separately)\n",
    "bundle = {\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"sensors\": SENSORS,\n",
    "    \"history_steps\": HISTORY_STEPS,\n",
    "    \"roll_windows\": ROLL_WINDOWS,\n",
    "    \"use_slope\": USE_SLOPE,\n",
    "    \"horizons\": HORIZONS,\n",
    "    \"models_meta\": {\n",
    "        h: {\n",
    "            \"name\": v[\"name\"],\n",
    "            \"test_rmse\": v[\"test_rmse\"],\n",
    "            \"test_mae\": v[\"test_mae\"],\n",
    "        }\n",
    "        for h, v in FINAL_MODELS.items()\n",
    "    },\n",
    "    \"scaler\": SCALER,\n",
    "    \"risk_label_column\": risk_col,\n",
    "}\n",
    "bundle_path = MODEL_REG / \"model3_forecast_bundle.joblib\"\n",
    "joblib.dump(bundle, bundle_path)\n",
    "print(\"\\nSaved forecast bundle:\", bundle_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbbe05f",
   "metadata": {},
   "source": [
    "Cell 11 — Summary CSV + example test forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac5f77f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+1h</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.014545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+24h</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.016879</td>\n",
       "      <td>0.014413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+3d</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.017158</td>\n",
       "      <td>0.014311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+6h</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.017120</td>\n",
       "      <td>0.014605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  horizon model_name  test_rmse  test_mae\n",
       "0     +1h      extra   0.017136  0.014545\n",
       "1    +24h      extra   0.016879  0.014413\n",
       "2     +3d      extra   0.017158  0.014311\n",
       "3     +6h      extra   0.017120  0.014605"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary to: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\reports\\model3_forecast_summary.csv\n",
      "\n",
      "Building test forecasts for horizon +1h ...\n",
      "  Saved: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\forecasts\\model3_test_forecasts_+1h.csv\n",
      "\n",
      "Building test forecasts for horizon +24h ...\n",
      "  Saved: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\forecasts\\model3_test_forecasts_+24h.csv\n",
      "\n",
      "Building test forecasts for horizon +3d ...\n",
      "  Saved: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\forecasts\\model3_test_forecasts_+3d.csv\n",
      "\n",
      "Building test forecasts for horizon +6h ...\n",
      "  Saved: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\forecasts\\model3_test_forecasts_+6h.csv\n",
      "\n",
      "Saved merged forecasts for all horizons to: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\forecasts\\model3_test_forecasts_all_horizons.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>true_+1h</th>\n",
       "      <th>pred_+1h</th>\n",
       "      <th>true_+24h</th>\n",
       "      <th>pred_+24h</th>\n",
       "      <th>true_+3d</th>\n",
       "      <th>pred_+3d</th>\n",
       "      <th>true_+6h</th>\n",
       "      <th>pred_+6h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-19 00:00:00</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.150452</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.148492</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.150859</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.152048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-19 00:30:00</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.152237</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>0.149879</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.149377</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.148498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-19 01:00:00</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.152325</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.149417</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.149047</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.149601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-19 01:30:00</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.151919</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>0.145995</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>0.148307</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>0.147752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-19 02:00:00</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.151068</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.147567</td>\n",
       "      <td>0.140539</td>\n",
       "      <td>0.147475</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>0.150078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  true_+1h  pred_+1h  true_+24h  pred_+24h  true_+3d  \\\n",
       "0 2025-03-19 00:00:00  0.140539  0.150452   0.140539   0.148492  0.140539   \n",
       "1 2025-03-19 00:30:00  0.140539  0.152237   0.177528   0.149879  0.140539   \n",
       "2 2025-03-19 01:00:00  0.140539  0.152325   0.140539   0.149417  0.140539   \n",
       "3 2025-03-19 01:30:00  0.140539  0.151919   0.177528   0.145995  0.177528   \n",
       "4 2025-03-19 02:00:00  0.140539  0.151068   0.140539   0.147567  0.140539   \n",
       "\n",
       "   pred_+3d  true_+6h  pred_+6h  \n",
       "0  0.150859  0.140539  0.152048  \n",
       "1  0.149377  0.140539  0.148498  \n",
       "2  0.149047  0.140539  0.149601  \n",
       "3  0.148307  0.177528  0.147752  \n",
       "4  0.147475  0.177528  0.150078  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 11 — Summary CSV + per-horizon test forecasts (no length mismatch)\n",
    "\n",
    "# Summary table\n",
    "summary_rows = []\n",
    "for h, obj in FINAL_MODELS.items():\n",
    "    summary_rows.append({\n",
    "        \"horizon\": h,\n",
    "        \"model_name\": obj[\"name\"],\n",
    "        \"test_rmse\": obj[\"test_rmse\"],\n",
    "        \"test_mae\": obj[\"test_mae\"],\n",
    "    })\n",
    "summary = pd.DataFrame(summary_rows).sort_values(\"horizon\")\n",
    "print(\"Forecasting summary:\")\n",
    "display(summary)\n",
    "\n",
    "summary_path = REPORTS / \"model3_forecast_summary.csv\"\n",
    "summary.to_csv(summary_path, index=False)\n",
    "print(\"Saved summary to:\", summary_path)\n",
    "\n",
    "# --- Per-horizon forecast exports ---\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "forecast_frames = []  # we'll collect per-horizon frames if you want a merged view at the end\n",
    "\n",
    "for h, obj in FINAL_MODELS.items():\n",
    "    print(f\"\\nBuilding test forecasts for horizon {h} ...\")\n",
    "    # Clean test block for this horizon\n",
    "    (_, _, _), (_, _, _), (Xte, yte, tte) = build_clean_blocks_for_horizon(\n",
    "        X_tr_s, X_va_s, X_te_s, feature_cols, h\n",
    "    )\n",
    "\n",
    "    # Predict\n",
    "    y_pred = obj[\"model\"].predict(Xte)\n",
    "\n",
    "    # Build a per-horizon DataFrame using that horizon's own timestamps\n",
    "    df_h = pd.DataFrame({\n",
    "        \"timestamp\": pd.to_datetime(tte),\n",
    "        f\"true_{h}\": yte,\n",
    "        f\"pred_{h}\": y_pred,\n",
    "    })\n",
    "\n",
    "    # Save individual horizon forecast\n",
    "    out_h = FORECASTS / f\"model3_test_forecasts_{h}.csv\"\n",
    "    df_h.to_csv(out_h, index=False)\n",
    "    print(\"  Saved:\", out_h)\n",
    "\n",
    "    forecast_frames.append(df_h)\n",
    "\n",
    "# Optionally merge all horizons on timestamp (outer join)\n",
    "if forecast_frames:\n",
    "    merged = reduce(lambda left, right: pd.merge(left, right, on=\"timestamp\", how=\"outer\"),\n",
    "                    forecast_frames)\n",
    "    merged_path = FORECASTS / \"model3_test_forecasts_all_horizons.csv\"\n",
    "    merged.to_csv(merged_path, index=False)\n",
    "    print(\"\\nSaved merged forecasts for all horizons to:\", merged_path)\n",
    "    display(merged.head())\n",
    "else:\n",
    "    print(\"No horizons produced forecasts (FINAL_MODELS is empty).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7bf51a",
   "metadata": {},
   "source": [
    "New Cell 12 — Import Keras & compute split boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfc89885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Time boundaries for sequences:\n",
      "Train end   : 2025-03-05 11:30:00\n",
      "Val end     : 2025-03-18 23:30:00\n",
      "Test start  : 2025-03-19 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Cell 12 — Deep learning setup (Keras + time boundaries from classical split)\n",
    "\n",
    "# Try importing TensorFlow / Keras\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "    HAVE_TF = True\n",
    "except Exception as e:\n",
    "    HAVE_TF = False\n",
    "    print(\"ERROR: TensorFlow/Keras not available. Install tensorflow before running deep models.\")\n",
    "    print(\"You can still run the classical models without this section.\")\n",
    "    raise e\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# We will reuse the same df, SENSORS, HORIZONS, HISTORY_STEPS, and the train/val/test boundaries.\n",
    "\n",
    "# Get time boundaries from your classical split (X_tr, X_va, X_te)\n",
    "TR_END = X_tr[\"timestamp\"].max()\n",
    "VA_END = X_va[\"timestamp\"].max()\n",
    "TE_START = X_te[\"timestamp\"].min()\n",
    "\n",
    "print(\"Time boundaries for sequences:\")\n",
    "print(\"Train end   :\", TR_END)\n",
    "print(\"Val end     :\", VA_END)\n",
    "print(\"Test start  :\", TE_START)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd78b206",
   "metadata": {},
   "source": [
    "New Cell 13 — Build sequence datasets per horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84b7b08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor scaler fitted on TRAIN subset.\n",
      "       temperature        pH  turbidity_proxy  predicted_do  predicted_nh3\n",
      "count     4345.000  4345.000         4345.000      4345.000       4345.000\n",
      "mean        -0.017     0.000            0.003        -0.019         -0.018\n",
      "std          1.010     1.004            0.993         0.994          0.945\n",
      "min         -3.308    -4.019           -3.604        -3.536         -2.304\n",
      "25%         -0.689    -0.666           -0.671        -0.737         -0.559\n",
      "50%         -0.015    -0.001            0.005         0.406         -0.163\n",
      "75%          0.647     0.669            0.676         0.406          0.438\n",
      "max          3.946     3.483            4.377         8.347         25.227\n",
      "\n",
      "=== Building sequences for horizon +1h (2 steps) ===\n",
      "Horizon step=2 | total seq=4319, train=3024, val=648, test=647\n",
      "\n",
      "=== Building sequences for horizon +6h (12 steps) ===\n",
      "Horizon step=12 | total seq=4309, train=3024, val=648, test=637\n",
      "\n",
      "=== Building sequences for horizon +24h (48 steps) ===\n",
      "Horizon step=48 | total seq=4273, train=3024, val=648, test=601\n",
      "\n",
      "=== Building sequences for horizon +3d (144 steps) ===\n",
      "Horizon step=144 | total seq=4177, train=3024, val=648, test=505\n",
      "\n",
      "Sequence datasets ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 13 — Sequence dataset builder for deep models\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1) Fit a scaler on the 5 sensors using only TRAIN period\n",
    "sensor_df = df.copy().sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "# Identify which rows are train/val/test based on timestamp\n",
    "is_train = sensor_df[\"timestamp\"] <= TR_END\n",
    "is_val   = (sensor_df[\"timestamp\"] > TR_END) & (sensor_df[\"timestamp\"] <= VA_END)\n",
    "is_test  = sensor_df[\"timestamp\"] > VA_END\n",
    "\n",
    "SENSORS_SCALER = StandardScaler()\n",
    "SENSORS_SCALER.fit(sensor_df.loc[is_train, SENSORS].astype(float))\n",
    "\n",
    "sensor_df[SENSORS] = SENSORS_SCALER.transform(sensor_df[SENSORS].astype(float))\n",
    "\n",
    "print(\"Sensor scaler fitted on TRAIN subset.\")\n",
    "print(sensor_df[SENSORS].describe().round(3))\n",
    "\n",
    "\n",
    "def build_sequence_dataset_for_horizon(df_in, sensors_cols, target_col, history_steps, horizon_steps):\n",
    "    \"\"\"\n",
    "    df_in: sorted by timestamp, contains sensors_cols + target_col\n",
    "    Returns:\n",
    "        (X_tr, y_tr), (X_va, y_va), (X_te, y_te)\n",
    "    where X_* shape = (n_samples, history_steps, len(sensors_cols))\n",
    "          y_* shape = (n_samples,)\n",
    "    \"\"\"\n",
    "    df_sorted = df_in.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    values = df_sorted[sensors_cols].values.astype(float)\n",
    "    target = df_sorted[target_col].values.astype(float)\n",
    "    timestamps = df_sorted[\"timestamp\"].values\n",
    "\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    t_seq = []\n",
    "\n",
    "    max_i = len(df_sorted) - horizon_steps  # ensure we have future target\n",
    "    for i in range(history_steps, max_i):\n",
    "        # sequence: [i-history_steps, ..., i-1]\n",
    "        seq = values[i-history_steps:i, :]\n",
    "        y   = target[i + horizon_steps]   # future horizon\n",
    "        t   = timestamps[i]               # we anchor sequence at \"current\" time\n",
    "\n",
    "        if np.isnan(seq).any() or np.isnan(y):\n",
    "            continue\n",
    "\n",
    "        X_seq.append(seq)\n",
    "        y_seq.append(y)\n",
    "        t_seq.append(t)\n",
    "\n",
    "    X_seq = np.array(X_seq, dtype=np.float32)\n",
    "    y_seq = np.array(y_seq, dtype=np.float32)\n",
    "    t_seq = np.array(t_seq)\n",
    "\n",
    "    # Split by timestamp boundaries TR_END / VA_END\n",
    "    is_tr_seq = t_seq <= TR_END\n",
    "    is_va_seq = (t_seq > TR_END) & (t_seq <= VA_END)\n",
    "    is_te_seq = t_seq > VA_END\n",
    "\n",
    "    X_tr = X_seq[is_tr_seq]\n",
    "    y_tr = y_seq[is_tr_seq]\n",
    "    X_va = X_seq[is_va_seq]\n",
    "    y_va = y_seq[is_va_seq]\n",
    "    X_te = X_seq[is_te_seq]\n",
    "    y_te = y_seq[is_te_seq]\n",
    "\n",
    "    print(f\"Horizon step={horizon_steps} | total seq={len(X_seq)}, \"\n",
    "          f\"train={len(X_tr)}, val={len(X_va)}, test={len(X_te)}\")\n",
    "\n",
    "    return (X_tr, y_tr), (X_va, y_va), (X_te, y_te)\n",
    "\n",
    "\n",
    "# Build datasets per horizon\n",
    "seq_datasets = {}  # hname -> {\"train\":(X_tr,y_tr), \"val\":(...), \"test\":(...)}\n",
    "\n",
    "for hname, step in HORIZONS.items():\n",
    "    print(f\"\\n=== Building sequences for horizon {hname} ({step} steps) ===\")\n",
    "    (X_tr_seq, y_tr_seq), (X_va_seq, y_va_seq), (X_te_seq, y_te_seq) = build_sequence_dataset_for_horizon(\n",
    "        sensor_df, SENSORS, \"p_high_target\", HISTORY_STEPS, step\n",
    "    )\n",
    "    seq_datasets[hname] = {\n",
    "        \"train\": (X_tr_seq, y_tr_seq),\n",
    "        \"val\":   (X_va_seq, y_va_seq),\n",
    "        \"test\":  (X_te_seq, y_te_seq),\n",
    "    }\n",
    "\n",
    "print(\"\\nSequence datasets ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696843eb",
   "metadata": {},
   "source": [
    "New Cell 14 — Define LSTM, GRU, and 1D-CNN builders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68ec067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14 — Deep model builders (LSTM, GRU, CNN)\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    input_shape: (timesteps, n_features)\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Masking(mask_value=0.0),\n",
    "        layers.LSTM(64, return_sequences=True),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.LSTM(32),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),  # output in [0,1]\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_gru_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.GRU(64, return_sequences=True),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.GRU(32),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_cnn1d_model(input_shape):\n",
    "    \"\"\"\n",
    "    1D CNN over time dimension.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv1D(32, kernel_size=3, padding=\"causal\", activation=\"relu\"),\n",
    "        layers.Conv1D(32, kernel_size=3, padding=\"causal\", activation=\"relu\"),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Conv1D(64, kernel_size=3, padding=\"causal\", activation=\"relu\"),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b0cea",
   "metadata": {},
   "source": [
    "New Cell 15 — Training loop for deep models per horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1d55e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Deep models for horizon +1h (2 steps) ================\n",
      "Train seq: (3024, 24, 5) | Val seq: (648, 24, 5) | Test seq: (647, 24, 5)\n",
      "\n",
      "--- Training LSTM for horizon +1h ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ masking (Masking)               │ (None, 24, 5)          │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ lstm (LSTM)                     │ (None, 24, 64)         │        17,920 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout (Dropout)               │ (None, 24, 64)         │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ lstm_1 (LSTM)                   │ (None, 32)             │        12,416 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_1 (Dropout)             │ (None, 32)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense (Dense)                   │ (None, 16)             │           528 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_1 (Dense)                 │ (None, 1)              │            17 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 30,881 (120.63 KB)\n",
      " Trainable params: 30,881 (120.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 0.0363 - mae: 0.1435 - val_loss: 5.6709e-04 - val_mae: 0.0215\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0015 - mae: 0.0300 - val_loss: 3.4007e-04 - val_mae: 0.0152\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 4.4145e-04 - val_mae: 0.0193\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0251 - val_loss: 3.5876e-04 - val_mae: 0.0167\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 9.0097e-04 - mae: 0.0227 - val_loss: 3.6101e-04 - val_mae: 0.0168\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 8.4560e-04 - mae: 0.0215 - val_loss: 3.3491e-04 - val_mae: 0.0151\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 7.8348e-04 - mae: 0.0206 - val_loss: 3.9756e-04 - val_mae: 0.0183\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 7.1626e-04 - mae: 0.0199 - val_loss: 3.6542e-04 - val_mae: 0.0172\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 6.7907e-04 - mae: 0.0193 - val_loss: 4.5460e-04 - val_mae: 0.0197\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.9719e-04 - mae: 0.0195 - val_loss: 3.6741e-04 - val_mae: 0.0173\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 6.9184e-04 - mae: 0.0194 - val_loss: 6.2918e-04 - val_mae: 0.0228\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM | Best epoch: 6 | Val RMSE ~ 0.0183\n",
      "LSTM | Test RMSE: 0.0167 | Test MAE: 0.0144\n",
      "Saved deep model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_deep_+1h_lstm.h5\n",
      "\n",
      "--- Training GRU for horizon +1h ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_1\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ gru (GRU)                       │ (None, 24, 64)         │        13,632 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_2 (Dropout)             │ (None, 24, 64)         │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ gru_1 (GRU)                     │ (None, 32)             │         9,408 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_3 (Dropout)             │ (None, 32)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_2 (Dense)                 │ (None, 16)             │           528 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_3 (Dense)                 │ (None, 1)              │            17 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 23,585 (92.13 KB)\n",
      " Trainable params: 23,585 (92.13 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 0.0368 - mae: 0.1541 - val_loss: 7.3061e-04 - val_mae: 0.0210\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0016 - mae: 0.0309 - val_loss: 5.0743e-04 - val_mae: 0.0173\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - mae: 0.0280 - val_loss: 4.3232e-04 - val_mae: 0.0159\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 4.0602e-04 - val_mae: 0.0148\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 9.8232e-04 - mae: 0.0239 - val_loss: 3.9362e-04 - val_mae: 0.0161\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 9.2775e-04 - mae: 0.0230 - val_loss: 4.1574e-04 - val_mae: 0.0174\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 8.6543e-04 - mae: 0.0219 - val_loss: 3.5647e-04 - val_mae: 0.0147\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 8.3187e-04 - mae: 0.0216 - val_loss: 3.8332e-04 - val_mae: 0.0169\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 8.0508e-04 - mae: 0.0212 - val_loss: 3.5096e-04 - val_mae: 0.0155\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 7.6180e-04 - mae: 0.0206 - val_loss: 3.8189e-04 - val_mae: 0.0172\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 7.0227e-04 - mae: 0.0197 - val_loss: 3.4881e-04 - val_mae: 0.0157\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 6.7710e-04 - mae: 0.0193 - val_loss: 6.8517e-04 - val_mae: 0.0233\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 6.5680e-04 - mae: 0.0186 - val_loss: 8.3292e-04 - val_mae: 0.0252\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 6.3737e-04 - mae: 0.0186 - val_loss: 6.1368e-04 - val_mae: 0.0224\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 6.1878e-04 - mae: 0.0183 - val_loss: 6.0903e-04 - val_mae: 0.0224\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 5.8931e-04 - mae: 0.0180 - val_loss: 6.3477e-04 - val_mae: 0.0227\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU | Best epoch: 11 | Val RMSE ~ 0.0187\n",
      "GRU | Test RMSE: 0.0174 | Test MAE: 0.0158\n",
      "Saved deep model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_deep_+1h_gru.h5\n",
      "\n",
      "--- Training CNN for horizon +1h ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_2\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ conv1d (Conv1D)                 │ (None, 24, 32)         │           512 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv1d_1 (Conv1D)               │ (None, 24, 32)         │         3,104 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ max_pooling1d (MaxPooling1D)    │ (None, 12, 32)         │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv1d_2 (Conv1D)               │ (None, 12, 64)         │         6,208 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ global_average_pooling1d        │ (None, 64)             │             0 │\n",
      "│ (GlobalAveragePooling1D)        │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_4 (Dropout)             │ (None, 64)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_4 (Dense)                 │ (None, 32)             │         2,080 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_5 (Dense)                 │ (None, 1)              │            33 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 11,937 (46.63 KB)\n",
      " Trainable params: 11,937 (46.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0212 - mae: 0.1056 - val_loss: 9.5162e-04 - val_mae: 0.0252\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mae: 0.0346 - val_loss: 7.2432e-04 - val_mae: 0.0205\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0322 - val_loss: 6.8737e-04 - val_mae: 0.0210\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0292 - val_loss: 6.4975e-04 - val_mae: 0.0201\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 6.5217e-04 - val_mae: 0.0206\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0259 - val_loss: 6.4531e-04 - val_mae: 0.0207\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mae: 0.0245 - val_loss: 6.4395e-04 - val_mae: 0.0209\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5813e-04 - mae: 0.0237 - val_loss: 5.5978e-04 - val_mae: 0.0191\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4724e-04 - mae: 0.0223 - val_loss: 6.2673e-04 - val_mae: 0.0208\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5029e-04 - mae: 0.0223 - val_loss: 5.0582e-04 - val_mae: 0.0181\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0143e-04 - mae: 0.0214 - val_loss: 5.5908e-04 - val_mae: 0.0197\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3036e-04 - mae: 0.0205 - val_loss: 5.2696e-04 - val_mae: 0.0192\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.7877e-04 - mae: 0.0195 - val_loss: 4.8105e-04 - val_mae: 0.0183\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4979e-04 - mae: 0.0192 - val_loss: 4.3803e-04 - val_mae: 0.0171\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0977e-04 - mae: 0.0186 - val_loss: 4.6828e-04 - val_mae: 0.0184\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7283e-04 - mae: 0.0180 - val_loss: 5.4771e-04 - val_mae: 0.0203\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3548e-04 - mae: 0.0173 - val_loss: 4.3248e-04 - val_mae: 0.0177\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1570e-04 - mae: 0.0168 - val_loss: 4.2632e-04 - val_mae: 0.0178\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0762e-04 - mae: 0.0168 - val_loss: 5.1838e-04 - val_mae: 0.0201\n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8415e-04 - mae: 0.0165 - val_loss: 3.9503e-04 - val_mae: 0.0171\n",
      "Epoch 21/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5953e-04 - mae: 0.0158 - val_loss: 3.8651e-04 - val_mae: 0.0169\n",
      "Epoch 22/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4795e-04 - mae: 0.0158 - val_loss: 3.6404e-04 - val_mae: 0.0161\n",
      "Epoch 23/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2941e-04 - mae: 0.0154 - val_loss: 3.8668e-04 - val_mae: 0.0173\n",
      "Epoch 24/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1566e-04 - mae: 0.0151 - val_loss: 3.5730e-04 - val_mae: 0.0161\n",
      "Epoch 25/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1498e-04 - mae: 0.0150 - val_loss: 3.5363e-04 - val_mae: 0.0160\n",
      "Epoch 26/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9886e-04 - mae: 0.0148 - val_loss: 3.4666e-04 - val_mae: 0.0157\n",
      "Epoch 27/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8906e-04 - mae: 0.0146 - val_loss: 3.4341e-04 - val_mae: 0.0156\n",
      "Epoch 28/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9831e-04 - mae: 0.0148 - val_loss: 3.6970e-04 - val_mae: 0.0171\n",
      "Epoch 29/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8186e-04 - mae: 0.0147 - val_loss: 3.3788e-04 - val_mae: 0.0153\n",
      "Epoch 30/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8255e-04 - mae: 0.0146 - val_loss: 3.3914e-04 - val_mae: 0.0156\n",
      "Epoch 31/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7928e-04 - mae: 0.0145 - val_loss: 3.4035e-04 - val_mae: 0.0158\n",
      "Epoch 32/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7729e-04 - mae: 0.0145 - val_loss: 3.3005e-04 - val_mae: 0.0149\n",
      "Epoch 33/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6876e-04 - mae: 0.0143 - val_loss: 3.5344e-04 - val_mae: 0.0166\n",
      "Epoch 34/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6541e-04 - mae: 0.0144 - val_loss: 3.3421e-04 - val_mae: 0.0154\n",
      "Epoch 35/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6409e-04 - mae: 0.0143 - val_loss: 3.3868e-04 - val_mae: 0.0158\n",
      "Epoch 36/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6457e-04 - mae: 0.0144 - val_loss: 3.3785e-04 - val_mae: 0.0158\n",
      "Epoch 37/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6428e-04 - mae: 0.0143 - val_loss: 3.3139e-04 - val_mae: 0.0151\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN | Best epoch: 32 | Val RMSE ~ 0.0182\n",
      "CNN | Test RMSE: 0.0170 | Test MAE: 0.0149\n",
      "Saved deep model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_deep_+1h_cnn.h5\n",
      "\n",
      "================ Deep models for horizon +6h (12 steps) ================\n",
      "Train seq: (3024, 24, 5) | Val seq: (648, 24, 5) | Test seq: (637, 24, 5)\n",
      "\n",
      "--- Training LSTM for horizon +6h ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_3\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ masking_1 (Masking)             │ (None, 24, 5)          │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ lstm_2 (LSTM)                   │ (None, 24, 64)         │        17,920 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_5 (Dropout)             │ (None, 24, 64)         │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ lstm_3 (LSTM)                   │ (None, 32)             │        12,416 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_6 (Dropout)             │ (None, 32)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_6 (Dense)                 │ (None, 16)             │           528 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_7 (Dense)                 │ (None, 1)              │            17 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 30,881 (120.63 KB)\n",
      " Trainable params: 30,881 (120.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 0.0302 - mae: 0.1288 - val_loss: 7.9037e-04 - val_mae: 0.0245\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 3.3977e-04 - val_mae: 0.0126\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 9.3923e-04 - mae: 0.0233 - val_loss: 3.2929e-04 - val_mae: 0.0146\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 8.7223e-04 - mae: 0.0220 - val_loss: 3.4870e-04 - val_mae: 0.0163\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.9365e-04 - mae: 0.0209 - val_loss: 3.2920e-04 - val_mae: 0.0148\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 8.0352e-04 - mae: 0.0213 - val_loss: 3.2908e-04 - val_mae: 0.0139\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.7583e-04 - mae: 0.0210 - val_loss: 3.4176e-04 - val_mae: 0.0160\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 7.3546e-04 - mae: 0.0203 - val_loss: 3.7190e-04 - val_mae: 0.0175\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.4144e-04 - mae: 0.0204 - val_loss: 3.9942e-04 - val_mae: 0.0183\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 7.1974e-04 - mae: 0.0199 - val_loss: 3.8085e-04 - val_mae: 0.0178\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 7.0428e-04 - mae: 0.0196 - val_loss: 4.1891e-04 - val_mae: 0.0189\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM | Best epoch: 6 | Val RMSE ~ 0.0181\n",
      "LSTM | Test RMSE: 0.0168 | Test MAE: 0.0140\n",
      "Saved deep model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_deep_+6h_lstm.h5\n",
      "\n",
      "--- Training GRU for horizon +6h ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_4\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ gru_2 (GRU)                     │ (None, 24, 64)         │        13,632 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_7 (Dropout)             │ (None, 24, 64)         │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ gru_3 (GRU)                     │ (None, 32)             │         9,408 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_8 (Dropout)             │ (None, 32)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_8 (Dense)                 │ (None, 16)             │           528 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_9 (Dense)                 │ (None, 1)              │            17 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 23,585 (92.13 KB)\n",
      " Trainable params: 23,585 (92.13 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 0.0232 - mae: 0.1124 - val_loss: 8.0689e-04 - val_mae: 0.0229\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0307 - val_loss: 4.3383e-04 - val_mae: 0.0158\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0013 - mae: 0.0285 - val_loss: 3.9955e-04 - val_mae: 0.0152\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0271 - val_loss: 3.8232e-04 - val_mae: 0.0147\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 3.8275e-04 - val_mae: 0.0142\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 9.6717e-04 - mae: 0.0236 - val_loss: 3.8235e-04 - val_mae: 0.0137\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 9.6470e-04 - mae: 0.0236 - val_loss: 3.5608e-04 - val_mae: 0.0146\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 8.7682e-04 - mae: 0.0226 - val_loss: 3.5843e-04 - val_mae: 0.0137\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 9.0148e-04 - mae: 0.0225 - val_loss: 3.7179e-04 - val_mae: 0.0124\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 8.4792e-04 - mae: 0.0220 - val_loss: 3.4782e-04 - val_mae: 0.0146\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 8.4789e-04 - mae: 0.0220 - val_loss: 4.2809e-04 - val_mae: 0.0184\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 7.6379e-04 - mae: 0.0209 - val_loss: 3.5655e-04 - val_mae: 0.0162\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 7.3007e-04 - mae: 0.0204 - val_loss: 3.4924e-04 - val_mae: 0.0160\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 7.1107e-04 - mae: 0.0199 - val_loss: 3.5906e-04 - val_mae: 0.0163\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 6.7730e-04 - mae: 0.0196 - val_loss: 4.1297e-04 - val_mae: 0.0184\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU | Best epoch: 10 | Val RMSE ~ 0.0186\n",
      "GRU | Test RMSE: 0.0178 | Test MAE: 0.0149\n",
      "Saved deep model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_deep_+6h_gru.h5\n",
      "\n",
      "--- Training CNN for horizon +6h ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_5\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ conv1d_3 (Conv1D)               │ (None, 24, 32)         │           512 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv1d_4 (Conv1D)               │ (None, 24, 32)         │         3,104 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ max_pooling1d_1 (MaxPooling1D)  │ (None, 12, 32)         │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv1d_5 (Conv1D)               │ (None, 12, 64)         │         6,208 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ global_average_pooling1d_1      │ (None, 64)             │             0 │\n",
      "│ (GlobalAveragePooling1D)        │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_9 (Dropout)             │ (None, 64)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_10 (Dense)                │ (None, 32)             │         2,080 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_11 (Dense)                │ (None, 1)              │            33 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 11,937 (46.63 KB)\n",
      " Trainable params: 11,937 (46.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0115 - mae: 0.0768 - val_loss: 7.1517e-04 - val_mae: 0.0213\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - mae: 0.0342 - val_loss: 6.5997e-04 - val_mae: 0.0204\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0310 - val_loss: 6.7346e-04 - val_mae: 0.0211\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0300 - val_loss: 6.4682e-04 - val_mae: 0.0208\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0010 - val_mae: 0.0273\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0259 - val_loss: 9.3782e-04 - val_mae: 0.0260\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mae: 0.0241 - val_loss: 9.2464e-04 - val_mae: 0.0259\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0242 - val_loss: 0.0016 - val_mae: 0.0351\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3476e-04 - mae: 0.0232 - val_loss: 0.0016 - val_mae: 0.0344\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN | Best epoch: 4 | Val RMSE ~ 0.0254\n",
      "CNN | Test RMSE: 0.0267 | Test MAE: 0.0218\n",
      "Saved deep model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_deep_+6h_cnn.h5\n",
      "\n",
      "================ Deep models for horizon +24h (48 steps) ================\n",
      "Train seq: (3024, 24, 5) | Val seq: (648, 24, 5) | Test seq: (601, 24, 5)\n",
      "\n",
      "--- Training LSTM for horizon +24h ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_6\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ masking_2 (Masking)             │ (None, 24, 5)          │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ lstm_4 (LSTM)                   │ (None, 24, 64)         │        17,920 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_10 (Dropout)            │ (None, 24, 64)         │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ lstm_5 (LSTM)                   │ (None, 32)             │        12,416 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_11 (Dropout)            │ (None, 32)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_12 (Dense)                │ (None, 16)             │           528 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_13 (Dense)                │ (None, 1)              │            17 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 30,881 (120.63 KB)\n",
      " Trainable params: 30,881 (120.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - loss: 0.0427 - mae: 0.1577 - val_loss: 4.0833e-04 - val_mae: 0.0185\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 3.4920e-04 - val_mae: 0.0109\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 3.8483e-04 - val_mae: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 9.6787e-04 - mae: 0.0234 - val_loss: 3.3653e-04 - val_mae: 0.0113\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 8.9199e-04 - mae: 0.0225 - val_loss: 3.1633e-04 - val_mae: 0.0133\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 8.2548e-04 - mae: 0.0215 - val_loss: 3.2116e-04 - val_mae: 0.0148\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 8.0255e-04 - mae: 0.0216 - val_loss: 3.1912e-04 - val_mae: 0.0146\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 7.7932e-04 - mae: 0.0207 - val_loss: 3.2554e-04 - val_mae: 0.0153\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 7.7839e-04 - mae: 0.0209 - val_loss: 3.1818e-04 - val_mae: 0.0145\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.6216e-04 - mae: 0.0206 - val_loss: 3.3479e-04 - val_mae: 0.0159\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM | Best epoch: 5 | Val RMSE ~ 0.0178\n",
      "LSTM | Test RMSE: 0.0168 | Test MAE: 0.0133\n",
      "Saved deep model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_deep_+24h_lstm.h5\n",
      "\n",
      "--- Training GRU for horizon +24h ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_7\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ gru_4 (GRU)                     │ (None, 24, 64)         │        13,632 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_12 (Dropout)            │ (None, 24, 64)         │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ gru_5 (GRU)                     │ (None, 32)             │         9,408 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_13 (Dropout)            │ (None, 32)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_14 (Dense)                │ (None, 16)             │           528 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_15 (Dense)                │ (None, 1)              │            17 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 23,585 (92.13 KB)\n",
      " Trainable params: 23,585 (92.13 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 0.0320 - mae: 0.1385 - val_loss: 0.0013 - val_mae: 0.0280\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0315 - val_loss: 4.1450e-04 - val_mae: 0.0158\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 3.7486e-04 - val_mae: 0.0148\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0256 - val_loss: 3.6093e-04 - val_mae: 0.0153\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0010 - mae: 0.0245 - val_loss: 3.4833e-04 - val_mae: 0.0136\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 9.6790e-04 - mae: 0.0236 - val_loss: 3.6039e-04 - val_mae: 0.0158\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 9.0878e-04 - mae: 0.0228 - val_loss: 3.4339e-04 - val_mae: 0.0132\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 8.8508e-04 - mae: 0.0225 - val_loss: 3.7320e-04 - val_mae: 0.0167\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 8.3478e-04 - mae: 0.0217 - val_loss: 3.4469e-04 - val_mae: 0.0157\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 7.6045e-04 - mae: 0.0209 - val_loss: 3.2973e-04 - val_mae: 0.0142\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 7.4181e-04 - mae: 0.0204 - val_loss: 3.2833e-04 - val_mae: 0.0139\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.3614e-04 - mae: 0.0203 - val_loss: 4.6030e-04 - val_mae: 0.0196\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 7.2195e-04 - mae: 0.0204 - val_loss: 3.8466e-04 - val_mae: 0.0176\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 6.9394e-04 - mae: 0.0197 - val_loss: 4.3490e-04 - val_mae: 0.0191\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 6.5499e-04 - mae: 0.0190 - val_loss: 4.3019e-04 - val_mae: 0.0190\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 6.4045e-04 - mae: 0.0188 - val_loss: 5.3778e-04 - val_mae: 0.0213\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU | Best epoch: 11 | Val RMSE ~ 0.0181\n",
      "GRU | Test RMSE: 0.0179 | Test MAE: 0.0150\n",
      "Saved deep model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_deep_+24h_gru.h5\n",
      "\n",
      "--- Training CNN for horizon +24h ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_8\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ conv1d_6 (Conv1D)               │ (None, 24, 32)         │           512 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv1d_7 (Conv1D)               │ (None, 24, 32)         │         3,104 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ max_pooling1d_2 (MaxPooling1D)  │ (None, 12, 32)         │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv1d_8 (Conv1D)               │ (None, 12, 64)         │         6,208 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ global_average_pooling1d_2      │ (None, 64)             │             0 │\n",
      "│ (GlobalAveragePooling1D)        │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_14 (Dropout)            │ (None, 64)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_16 (Dense)                │ (None, 32)             │         2,080 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_17 (Dense)                │ (None, 1)              │            33 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 11,937 (46.63 KB)\n",
      " Trainable params: 11,937 (46.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0147 - mae: 0.0861 - val_loss: 0.0013 - val_mae: 0.0294\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - mae: 0.0339 - val_loss: 8.1739e-04 - val_mae: 0.0224\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0318 - val_loss: 8.0826e-04 - val_mae: 0.0224\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0290 - val_loss: 7.5900e-04 - val_mae: 0.0218\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 7.0758e-04 - val_mae: 0.0209\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 8.9015e-04 - val_mae: 0.0242\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 9.1447e-04 - val_mae: 0.0247\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4206e-04 - mae: 0.0233 - val_loss: 9.9209e-04 - val_mae: 0.0259\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.7089e-04 - mae: 0.0223 - val_loss: 8.5677e-04 - val_mae: 0.0241\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0225e-04 - mae: 0.0215 - val_loss: 0.0011 - val_mae: 0.0274\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN | Best epoch: 5 | Val RMSE ~ 0.0266\n",
      "CNN | Test RMSE: 0.0265 | Test MAE: 0.0226\n",
      "Saved deep model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_deep_+24h_cnn.h5\n",
      "\n",
      "================ Deep models for horizon +3d (144 steps) ================\n",
      "Train seq: (3024, 24, 5) | Val seq: (648, 24, 5) | Test seq: (505, 24, 5)\n",
      "\n",
      "--- Training LSTM for horizon +3d ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_9\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ masking_3 (Masking)             │ (None, 24, 5)          │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ lstm_6 (LSTM)                   │ (None, 24, 64)         │        17,920 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_15 (Dropout)            │ (None, 24, 64)         │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ lstm_7 (LSTM)                   │ (None, 32)             │        12,416 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_16 (Dropout)            │ (None, 32)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_18 (Dense)                │ (None, 16)             │           528 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_19 (Dense)                │ (None, 1)              │            17 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 30,881 (120.63 KB)\n",
      " Trainable params: 30,881 (120.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 0.0329 - mae: 0.1311 - val_loss: 4.4863e-04 - val_mae: 0.0196\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0011 - mae: 0.0259 - val_loss: 3.2738e-04 - val_mae: 0.0125\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0010 - mae: 0.0242 - val_loss: 3.2690e-04 - val_mae: 0.0149\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 9.3565e-04 - mae: 0.0231 - val_loss: 3.2112e-04 - val_mae: 0.0141\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 8.8025e-04 - mae: 0.0223 - val_loss: 3.2453e-04 - val_mae: 0.0148\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 7.9240e-04 - mae: 0.0213 - val_loss: 3.3020e-04 - val_mae: 0.0120\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.9605e-04 - mae: 0.0211 - val_loss: 3.2154e-04 - val_mae: 0.0146\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.2234e-04 - mae: 0.0201 - val_loss: 3.2183e-04 - val_mae: 0.0146\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 7.1061e-04 - mae: 0.0199 - val_loss: 3.3339e-04 - val_mae: 0.0157\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM | Best epoch: 4 | Val RMSE ~ 0.0179\n",
      "LSTM | Test RMSE: 0.0170 | Test MAE: 0.0141\n",
      "Saved deep model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_deep_+3d_lstm.h5\n",
      "\n",
      "--- Training GRU for horizon +3d ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_10\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ gru_6 (GRU)                     │ (None, 24, 64)         │        13,632 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_17 (Dropout)            │ (None, 24, 64)         │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ gru_7 (GRU)                     │ (None, 32)             │         9,408 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_18 (Dropout)            │ (None, 32)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_20 (Dense)                │ (None, 16)             │           528 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_21 (Dense)                │ (None, 1)              │            17 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 23,585 (92.13 KB)\n",
      " Trainable params: 23,585 (92.13 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 0.0255 - mae: 0.1219 - val_loss: 0.0011 - val_mae: 0.0270\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0329 - val_loss: 6.0048e-04 - val_mae: 0.0183\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0015 - mae: 0.0303 - val_loss: 5.2148e-04 - val_mae: 0.0161\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0280 - val_loss: 4.4284e-04 - val_mae: 0.0150\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - mae: 0.0263 - val_loss: 4.5377e-04 - val_mae: 0.0146\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 3.9412e-04 - val_mae: 0.0154\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0010 - mae: 0.0247 - val_loss: 3.9693e-04 - val_mae: 0.0134\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 9.3260e-04 - mae: 0.0232 - val_loss: 3.7039e-04 - val_mae: 0.0153\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 9.1309e-04 - mae: 0.0229 - val_loss: 4.3932e-04 - val_mae: 0.0130\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 8.4177e-04 - mae: 0.0218 - val_loss: 3.5714e-04 - val_mae: 0.0137\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 8.1400e-04 - mae: 0.0217 - val_loss: 3.4922e-04 - val_mae: 0.0132\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 8.0913e-04 - mae: 0.0213 - val_loss: 3.6054e-04 - val_mae: 0.0159\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.7248e-04 - mae: 0.0209 - val_loss: 3.3577e-04 - val_mae: 0.0141\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.1463e-04 - mae: 0.0200 - val_loss: 3.2974e-04 - val_mae: 0.0139\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 7.1182e-04 - mae: 0.0199 - val_loss: 3.3274e-04 - val_mae: 0.0145\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 6.6555e-04 - mae: 0.0191 - val_loss: 3.6317e-04 - val_mae: 0.0169\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6.6136e-04 - mae: 0.0190 - val_loss: 3.5654e-04 - val_mae: 0.0167\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.5630e-04 - mae: 0.0188 - val_loss: 4.5864e-04 - val_mae: 0.0197\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.3363e-04 - mae: 0.0187 - val_loss: 4.1925e-04 - val_mae: 0.0187\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU | Best epoch: 14 | Val RMSE ~ 0.0182\n",
      "GRU | Test RMSE: 0.0173 | Test MAE: 0.0145\n",
      "Saved deep model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_deep_+3d_gru.h5\n",
      "\n",
      "--- Training CNN for horizon +3d ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_11\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ conv1d_9 (Conv1D)               │ (None, 24, 32)         │           512 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv1d_10 (Conv1D)              │ (None, 24, 32)         │         3,104 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ max_pooling1d_3 (MaxPooling1D)  │ (None, 12, 32)         │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv1d_11 (Conv1D)              │ (None, 12, 64)         │         6,208 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ global_average_pooling1d_3      │ (None, 64)             │             0 │\n",
      "│ (GlobalAveragePooling1D)        │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_19 (Dropout)            │ (None, 64)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_22 (Dense)                │ (None, 32)             │         2,080 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_23 (Dense)                │ (None, 1)              │            33 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 11,937 (46.63 KB)\n",
      " Trainable params: 11,937 (46.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0120 - mae: 0.0804 - val_loss: 8.4879e-04 - val_mae: 0.0221\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - mae: 0.0344 - val_loss: 8.8443e-04 - val_mae: 0.0236\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0301 - val_loss: 7.7295e-04 - val_mae: 0.0220\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0280 - val_loss: 9.1329e-04 - val_mae: 0.0244\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0257 - val_loss: 7.6486e-04 - val_mae: 0.0221\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 9.0194e-04 - val_mae: 0.0246\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4996e-04 - mae: 0.0234 - val_loss: 6.2822e-04 - val_mae: 0.0200\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7868e-04 - mae: 0.0226 - val_loss: 7.8381e-04 - val_mae: 0.0229\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4345e-04 - mae: 0.0222 - val_loss: 6.0797e-04 - val_mae: 0.0200\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8966e-04 - mae: 0.0214 - val_loss: 6.4923e-04 - val_mae: 0.0209\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0615e-04 - mae: 0.0200 - val_loss: 6.1048e-04 - val_mae: 0.0204\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3752e-04 - mae: 0.0206 - val_loss: 5.5127e-04 - val_mae: 0.0194\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8486e-04 - mae: 0.0196 - val_loss: 9.1003e-04 - val_mae: 0.0259\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3815e-04 - mae: 0.0188 - val_loss: 9.9408e-04 - val_mae: 0.0272\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3251e-04 - mae: 0.0189 - val_loss: 7.3446e-04 - val_mae: 0.0234\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8502e-04 - mae: 0.0181 - val_loss: 6.2285e-04 - val_mae: 0.0217\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5992e-04 - mae: 0.0176 - val_loss: 7.9482e-04 - val_mae: 0.0245\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN | Best epoch: 12 | Val RMSE ~ 0.0235\n",
      "CNN | Test RMSE: 0.0245 | Test MAE: 0.0218\n",
      "Saved deep model: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_deep_+3d_cnn.h5\n",
      "\n",
      "Deep models training complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>model_type</th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>best_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+1h</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.016739</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+1h</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.018167</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>0.014945</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+1h</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.018676</td>\n",
       "      <td>0.017427</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>+24h</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.017786</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>0.013262</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>+24h</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.018120</td>\n",
       "      <td>0.017862</td>\n",
       "      <td>0.014983</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>+24h</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.026524</td>\n",
       "      <td>0.022587</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>+3d</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.017920</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.014126</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>+3d</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.018159</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>0.014537</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>+3d</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.023479</td>\n",
       "      <td>0.024530</td>\n",
       "      <td>0.021797</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+6h</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.018141</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+6h</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>0.017771</td>\n",
       "      <td>0.014868</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>+6h</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.025433</td>\n",
       "      <td>0.026694</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   horizon model_type  val_rmse  test_rmse  test_mae  best_epoch\n",
       "0      +1h       lstm  0.018301   0.016739  0.014402           6\n",
       "2      +1h        cnn  0.018167   0.016998  0.014945          32\n",
       "1      +1h        gru  0.018676   0.017427  0.015761          11\n",
       "6     +24h       lstm  0.017786   0.016771  0.013262           5\n",
       "7     +24h        gru  0.018120   0.017862  0.014983          11\n",
       "8     +24h        cnn  0.026600   0.026524  0.022587           5\n",
       "9      +3d       lstm  0.017920   0.016966  0.014126           4\n",
       "10     +3d        gru  0.018159   0.017259  0.014537          14\n",
       "11     +3d        cnn  0.023479   0.024530  0.021797          12\n",
       "3      +6h       lstm  0.018141   0.016758  0.013992           6\n",
       "4      +6h        gru  0.018650   0.017771  0.014868          10\n",
       "5      +6h        cnn  0.025433   0.026694  0.021840           4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 15 — Train deep models (LSTM/GRU/CNN) per horizon\n",
    "\n",
    "import math\n",
    "\n",
    "def rmse_np(y_true, y_pred):\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "def mae_np(y_true, y_pred):\n",
    "    return float(np.mean(np.abs(y_true - y_pred)))\n",
    "\n",
    "MAX_EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "PATIENCE   = 5\n",
    "\n",
    "deep_results = []       # rows: {horizon, model_type, test_rmse, test_mae, val_rmse, best_epoch}\n",
    "DEEP_MODELS  = {}       # nested dict: DEEP_MODELS[hname][arch] = model\n",
    "\n",
    "for hname, step in HORIZONS.items():\n",
    "    print(f\"\\n================ Deep models for horizon {hname} ({step} steps) ================\")\n",
    "\n",
    "    ds = seq_datasets[hname]\n",
    "    X_tr_seq, y_tr_seq = ds[\"train\"]\n",
    "    X_va_seq, y_va_seq = ds[\"val\"]\n",
    "    X_te_seq, y_te_seq = ds[\"test\"]\n",
    "\n",
    "    print(\"Train seq:\", X_tr_seq.shape, \"| Val seq:\", X_va_seq.shape, \"| Test seq:\", X_te_seq.shape)\n",
    "\n",
    "    # Require a minimum amount of data\n",
    "    if len(X_tr_seq) < 200 or len(X_va_seq) < 50 or len(X_te_seq) < 50:\n",
    "        print(\"Not enough sequence data for deep models on this horizon. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    input_shape = X_tr_seq.shape[1:]  # (timesteps, features)\n",
    "\n",
    "    # Prepare architectures\n",
    "    arch_builders = {\n",
    "        \"lstm\": build_lstm_model,\n",
    "        \"gru\":  build_gru_model,\n",
    "        \"cnn\":  build_cnn1d_model,\n",
    "    }\n",
    "\n",
    "    DEEP_MODELS[hname] = {}\n",
    "\n",
    "    for arch_name, builder in arch_builders.items():\n",
    "        print(f\"\\n--- Training {arch_name.upper()} for horizon {hname} ---\")\n",
    "        model = builder(input_shape)\n",
    "        model.summary(print_fn=lambda x: print(\"   \" + x))\n",
    "\n",
    "        es = callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=PATIENCE,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            X_tr_seq, y_tr_seq,\n",
    "            validation_data=(X_va_seq, y_va_seq),\n",
    "            epochs=MAX_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=[es],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Best epoch is len(history.history[\"loss\"]) - patience_offset, but\n",
    "        # simpler: get min val_loss epoch\n",
    "        val_losses = history.history[\"val_loss\"]\n",
    "        best_epoch = int(np.argmin(val_losses)) + 1\n",
    "        best_val_rmse = math.sqrt(val_losses[best_epoch-1])\n",
    "\n",
    "        # Evaluate on test\n",
    "        y_pred_te = model.predict(X_te_seq).reshape(-1)\n",
    "        test_rmse = rmse_np(y_te_seq, y_pred_te)\n",
    "        test_mae  = mae_np(y_te_seq, y_pred_te)\n",
    "\n",
    "        print(f\"{arch_name.upper()} | Best epoch: {best_epoch} | Val RMSE ~ {best_val_rmse:.4f}\")\n",
    "        print(f\"{arch_name.upper()} | Test RMSE: {test_rmse:.4f} | Test MAE: {test_mae:.4f}\")\n",
    "\n",
    "        deep_results.append({\n",
    "            \"horizon\": hname,\n",
    "            \"model_type\": arch_name,\n",
    "            \"val_rmse\": float(best_val_rmse),\n",
    "            \"test_rmse\": float(test_rmse),\n",
    "            \"test_mae\": float(test_mae),\n",
    "            \"best_epoch\": int(best_epoch),\n",
    "        })\n",
    "\n",
    "        # Save model\n",
    "        save_path = MODEL_REG / f\"model3_deep_{hname}_{arch_name}.h5\"\n",
    "        model.save(save_path)\n",
    "        print(\"Saved deep model:\", save_path)\n",
    "\n",
    "        DEEP_MODELS[hname][arch_name] = model\n",
    "\n",
    "print(\"\\nDeep models training complete.\")\n",
    "deep_results_df = pd.DataFrame(deep_results)\n",
    "display(deep_results_df.sort_values([\"horizon\",\"test_rmse\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbcb668",
   "metadata": {},
   "source": [
    "New Cell 16 — Compare classical vs deep models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1dfad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>model_family</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+1h</td>\n",
       "      <td>classical_extra</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.014545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+24h</td>\n",
       "      <td>classical_extra</td>\n",
       "      <td>0.016879</td>\n",
       "      <td>0.014413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+3d</td>\n",
       "      <td>classical_extra</td>\n",
       "      <td>0.017158</td>\n",
       "      <td>0.014311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+6h</td>\n",
       "      <td>classical_extra</td>\n",
       "      <td>0.017120</td>\n",
       "      <td>0.014605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  horizon     model_family  test_rmse  test_mae\n",
       "0     +1h  classical_extra   0.017136  0.014545\n",
       "1    +24h  classical_extra   0.016879  0.014413\n",
       "2     +3d  classical_extra   0.017158  0.014311\n",
       "3     +6h  classical_extra   0.017120  0.014605"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>model_type</th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>best_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+1h</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.016739</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+1h</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.018167</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>0.014945</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+1h</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.018676</td>\n",
       "      <td>0.017427</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>+24h</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.017786</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>0.013262</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>+24h</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.018120</td>\n",
       "      <td>0.017862</td>\n",
       "      <td>0.014983</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>+24h</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.026524</td>\n",
       "      <td>0.022587</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>+3d</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.017920</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.014126</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>+3d</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.018159</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>0.014537</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>+3d</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.023479</td>\n",
       "      <td>0.024530</td>\n",
       "      <td>0.021797</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+6h</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.018141</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+6h</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>0.017771</td>\n",
       "      <td>0.014868</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>+6h</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.025433</td>\n",
       "      <td>0.026694</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   horizon model_type  val_rmse  test_rmse  test_mae  best_epoch\n",
       "0      +1h       lstm  0.018301   0.016739  0.014402           6\n",
       "2      +1h        cnn  0.018167   0.016998  0.014945          32\n",
       "1      +1h        gru  0.018676   0.017427  0.015761          11\n",
       "6     +24h       lstm  0.017786   0.016771  0.013262           5\n",
       "7     +24h        gru  0.018120   0.017862  0.014983          11\n",
       "8     +24h        cnn  0.026600   0.026524  0.022587           5\n",
       "9      +3d       lstm  0.017920   0.016966  0.014126           4\n",
       "10     +3d        gru  0.018159   0.017259  0.014537          14\n",
       "11     +3d        cnn  0.023479   0.024530  0.021797          12\n",
       "3      +6h       lstm  0.018141   0.016758  0.013992           6\n",
       "4      +6h        gru  0.018650   0.017771  0.014868          10\n",
       "5      +6h        cnn  0.025433   0.026694  0.021840           4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical vs best Deep per horizon:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>model_family</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>deep_model_type</th>\n",
       "      <th>deep_test_rmse</th>\n",
       "      <th>deep_test_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+1h</td>\n",
       "      <td>classical_extra</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.016739</td>\n",
       "      <td>0.014402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+24h</td>\n",
       "      <td>classical_extra</td>\n",
       "      <td>0.016879</td>\n",
       "      <td>0.014413</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>0.013262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+3d</td>\n",
       "      <td>classical_extra</td>\n",
       "      <td>0.017158</td>\n",
       "      <td>0.014311</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.014126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+6h</td>\n",
       "      <td>classical_extra</td>\n",
       "      <td>0.017120</td>\n",
       "      <td>0.014605</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.013992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  horizon     model_family  test_rmse  test_mae deep_model_type  \\\n",
       "0     +1h  classical_extra   0.017136  0.014545            lstm   \n",
       "1    +24h  classical_extra   0.016879  0.014413            lstm   \n",
       "2     +3d  classical_extra   0.017158  0.014311            lstm   \n",
       "3     +6h  classical_extra   0.017120  0.014605            lstm   \n",
       "\n",
       "   deep_test_rmse  deep_test_mae  \n",
       "0        0.016739       0.014402  \n",
       "1        0.016771       0.013262  \n",
       "2        0.016966       0.014126  \n",
       "3        0.016758       0.013992  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 16 — Classical vs Deep: comparison table\n",
    "\n",
    "# classical summary: best_by_h or res_df/best_by_h from earlier\n",
    "# We already had `best_by_h` and `summary` (classical).\n",
    "# Let's reconstruct a simple classical summary from FINAL_MODELS:\n",
    "\n",
    "classical_summary_rows = []\n",
    "for h, obj in FINAL_MODELS.items():\n",
    "    classical_summary_rows.append({\n",
    "        \"horizon\": h,\n",
    "        \"model_family\": \"classical_\" + obj[\"name\"],\n",
    "        \"test_rmse\": obj[\"test_rmse\"],\n",
    "        \"test_mae\": obj[\"test_mae\"],\n",
    "    })\n",
    "classical_summary_df = pd.DataFrame(classical_summary_rows)\n",
    "\n",
    "print(\"Classical models:\")\n",
    "display(classical_summary_df.sort_values(\"horizon\"))\n",
    "\n",
    "print(\"Deep models:\")\n",
    "display(deep_results_df.sort_values([\"horizon\",\"test_rmse\"]))\n",
    "\n",
    "# Merge on horizon for high-level comparison (best deep per horizon)\n",
    "best_deep_by_h = (deep_results_df.sort_values([\"horizon\",\"test_rmse\"])\n",
    "                  .groupby(\"horizon\").head(1)\n",
    "                  .rename(columns={\"model_type\":\"deep_model_type\",\n",
    "                                   \"test_rmse\":\"deep_test_rmse\",\n",
    "                                   \"test_mae\":\"deep_test_mae\"}))\n",
    "\n",
    "cmp = pd.merge(\n",
    "    classical_summary_df,\n",
    "    best_deep_by_h[[\"horizon\",\"deep_model_type\",\"deep_test_rmse\",\"deep_test_mae\"]],\n",
    "    on=\"horizon\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"Classical vs best Deep per horizon:\")\n",
    "display(cmp.sort_values(\"horizon\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1890d",
   "metadata": {},
   "source": [
    "Hybrid Finalization Cell (Choose hybrid models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6281bbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing hybrid forecast models (classical vs deep)...\n",
      "\n",
      "=== Horizon +1h ===\n",
      "  Classical:      extra | RMSE=0.017136 | MAE=0.014545\n",
      "  Best Deep:       lstm | RMSE=0.016739 | MAE=0.014402\n",
      "  -> Choosing DEEP (lstm) for +1h\n",
      "=== Horizon +24h ===\n",
      "  Classical:      extra | RMSE=0.016879 | MAE=0.014413\n",
      "  Best Deep:       lstm | RMSE=0.016771 | MAE=0.013262\n",
      "  -> Keeping CLASSICAL (extra) for +24h\n",
      "=== Horizon +3d ===\n",
      "  Classical:      extra | RMSE=0.017158 | MAE=0.014311\n",
      "  Best Deep:       lstm | RMSE=0.016966 | MAE=0.014126\n",
      "  -> Keeping CLASSICAL (extra) for +3d\n",
      "=== Horizon +6h ===\n",
      "  Classical:      extra | RMSE=0.017120 | MAE=0.014605\n",
      "  Best Deep:       lstm | RMSE=0.016758 | MAE=0.013992\n",
      "  -> Choosing DEEP (lstm) for +6h\n",
      "\n",
      "Hybrid horizon selection (classical vs deep):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>chosen_family</th>\n",
       "      <th>chosen_algo</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>model_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+1h</td>\n",
       "      <td>deep</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.016739</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>C:\\Users\\PC\\Documents\\Machine_Learning\\Capston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+24h</td>\n",
       "      <td>classical</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.016879</td>\n",
       "      <td>0.014413</td>\n",
       "      <td>C:\\Users\\PC\\Documents\\Machine_Learning\\Capston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+3d</td>\n",
       "      <td>classical</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.017158</td>\n",
       "      <td>0.014311</td>\n",
       "      <td>C:\\Users\\PC\\Documents\\Machine_Learning\\Capston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+6h</td>\n",
       "      <td>deep</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>C:\\Users\\PC\\Documents\\Machine_Learning\\Capston...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  horizon chosen_family chosen_algo  test_rmse  test_mae  \\\n",
       "0     +1h          deep        lstm   0.016739  0.014402   \n",
       "1    +24h     classical       extra   0.016879  0.014413   \n",
       "2     +3d     classical       extra   0.017158  0.014311   \n",
       "3     +6h          deep        lstm   0.016758  0.013992   \n",
       "\n",
       "                                          model_path  \n",
       "0  C:\\Users\\PC\\Documents\\Machine_Learning\\Capston...  \n",
       "1  C:\\Users\\PC\\Documents\\Machine_Learning\\Capston...  \n",
       "2  C:\\Users\\PC\\Documents\\Machine_Learning\\Capston...  \n",
       "3  C:\\Users\\PC\\Documents\\Machine_Learning\\Capston...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved hybrid forecast bundle to: C:\\Users\\PC\\Documents\\Machine_Learning\\Capstone_Project\\Poseidon\\artifacts\\model_registry\\model3_forecast_hybrid_bundle.joblib\n"
     ]
    }
   ],
   "source": [
    "# Cell 17 — Hybrid finalization: choose best (classical vs deep) per horizon and save bundle\n",
    "\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Safety checks\n",
    "assert \"FINAL_MODELS\" in globals(), \"FINAL_MODELS (classical) not found — run classical cells first.\"\n",
    "assert \"deep_results_df\" in globals(), \"deep_results_df not found — run deep training cells first.\"\n",
    "\n",
    "print(\"Finalizing hybrid forecast models (classical vs deep)...\\n\")\n",
    "\n",
    "HYBRID_MODELS = []  # list of rows for a summary table\n",
    "HYBRID_META   = {}  # for saving in the bundle, keyed by horizon\n",
    "\n",
    "# We'll use a small margin so that tiny differences don't flip decisions.\n",
    "# If deep is only microscopically better (< margin), we can still prefer classical for simplicity.\n",
    "RMSE_MARGIN = 0.0002  # tweak if desired\n",
    "\n",
    "for h in sorted(HORIZONS.keys()):\n",
    "    print(f\"=== Horizon {h} ===\")\n",
    "\n",
    "    # ---- Classical info ----\n",
    "    classical = FINAL_MODELS.get(h)\n",
    "    if classical is None:\n",
    "        print(f\"  No classical model registered for {h}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    cls_rmse = classical[\"test_rmse\"]\n",
    "    cls_mae  = classical[\"test_mae\"]\n",
    "    cls_name = classical[\"name\"]\n",
    "    # We assume classical models were already saved as:\n",
    "    # MODEL_REG / f\"model3_{h}_{cls_name}.joblib\"\n",
    "    cls_path = MODEL_REG / f\"model3_{h}_{cls_name}.joblib\"\n",
    "\n",
    "    # ---- Deep info ----\n",
    "    deep_rows = deep_results_df[deep_results_df[\"horizon\"] == h]\n",
    "    has_deep = len(deep_rows) > 0\n",
    "\n",
    "    chosen_family = \"classical\"\n",
    "    chosen_algo   = cls_name\n",
    "    chosen_rmse   = cls_rmse\n",
    "    chosen_mae    = cls_mae\n",
    "    chosen_path   = str(cls_path)\n",
    "    chosen_arch   = None\n",
    "\n",
    "    if has_deep:\n",
    "        best_deep = (deep_rows.sort_values(\"test_rmse\").iloc[0]).to_dict()\n",
    "        dp_rmse = best_deep[\"test_rmse\"]\n",
    "        dp_mae  = best_deep[\"test_mae\"]\n",
    "        dp_arch = best_deep[\"model_type\"]  # \"lstm\", \"gru\", or \"cnn\"\n",
    "\n",
    "        print(f\"  Classical: {cls_name:>10s} | RMSE={cls_rmse:.6f} | MAE={cls_mae:.6f}\")\n",
    "        print(f\"  Best Deep: {dp_arch:>10s} | RMSE={dp_rmse:.6f} | MAE={dp_mae:.6f}\")\n",
    "\n",
    "        # Decide which to keep\n",
    "        if dp_rmse + RMSE_MARGIN < cls_rmse:\n",
    "            # Deep meaningfully better → choose deep\n",
    "            chosen_family = \"deep\"\n",
    "            chosen_algo   = dp_arch\n",
    "            chosen_rmse   = dp_rmse\n",
    "            chosen_mae    = dp_mae\n",
    "            chosen_arch   = dp_arch\n",
    "\n",
    "            # Deep models were saved in Cell 15 as:\n",
    "            # MODEL_REG / f\"model3_deep_{h}_{arch_name}.h5\"\n",
    "            deep_path = MODEL_REG / f\"model3_deep_{h}_{dp_arch}.h5\"\n",
    "            chosen_path = str(deep_path)\n",
    "\n",
    "            print(f\"  -> Choosing DEEP ({dp_arch}) for {h}\")\n",
    "        else:\n",
    "            # Classical still competitive / simpler\n",
    "            print(f\"  -> Keeping CLASSICAL ({cls_name}) for {h}\")\n",
    "    else:\n",
    "        print(f\"  No deep models for {h}. Using classical ({cls_name}).\")\n",
    "\n",
    "    HYBRID_MODELS.append({\n",
    "        \"horizon\": h,\n",
    "        \"chosen_family\": chosen_family,    # \"classical\" or \"deep\"\n",
    "        \"chosen_algo\": chosen_algo,        # e.g. \"extra\", \"lstm\"\n",
    "        \"test_rmse\": chosen_rmse,\n",
    "        \"test_mae\": chosen_mae,\n",
    "        \"model_path\": chosen_path,\n",
    "    })\n",
    "\n",
    "    HYBRID_META[h] = {\n",
    "        \"family\": chosen_family,\n",
    "        \"algo\": chosen_algo,\n",
    "        \"test_rmse\": chosen_rmse,\n",
    "        \"test_mae\": chosen_mae,\n",
    "        \"model_path\": chosen_path,\n",
    "    }\n",
    "\n",
    "# Turn into a DataFrame for inspection\n",
    "hybrid_df = pd.DataFrame(HYBRID_MODELS).sort_values(\"horizon\")\n",
    "print(\"\\nHybrid horizon selection (classical vs deep):\")\n",
    "display(hybrid_df)\n",
    "\n",
    "# ---- Save hybrid bundle ----\n",
    "# We store:\n",
    "#   - tabular feature columns & scaler (for classical)\n",
    "#   - sensors & sensors scaler (for deep sequence models)\n",
    "#   - horizons, history steps, roll windows, etc.\n",
    "#   - which model family/arch is used per horizon and where it's saved.\n",
    "\n",
    "hybrid_bundle = {\n",
    "    \"feature_cols\": feature_cols,          # used by classical models\n",
    "    \"sensors\": SENSORS,                    # raw sensor names\n",
    "    \"history_steps\": HISTORY_STEPS,        # for sequence models\n",
    "    \"roll_windows\": ROLL_WINDOWS,\n",
    "    \"use_slope\": USE_SLOPE,\n",
    "    \"horizons\": HORIZONS,\n",
    "    \"risk_label_column\": risk_col,         # e.g. \"risk_blended\" or similar\n",
    "    \"scaler_tabular\": SCALER,              # StandardScaler for tabular features\n",
    "    \"scaler_sensors\": SENSORS_SCALER,      # StandardScaler for sensor sequences\n",
    "    \"hybrid_models\": HYBRID_META,          # per-horizon metadata\n",
    "}\n",
    "\n",
    "hybrid_bundle_path = MODEL_REG / \"model3_forecast_hybrid_bundle.joblib\"\n",
    "joblib.dump(hybrid_bundle, hybrid_bundle_path)\n",
    "print(\"\\nSaved hybrid forecast bundle to:\", hybrid_bundle_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56127f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "715d1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path:\", sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Ensure repo root is on sys.path so 'src' can be imported from notebooks/\n",
    "# If your notebook is under the repo's 'notebooks/' folder this goes up one level.\n",
    "nb_cwd = Path.cwd()\n",
    "repo_root = nb_cwd\n",
    "if not (repo_root / \"src\").exists():\n",
    "    repo_root = nb_cwd.parent  # move up if notebook CWD is notebooks/\n",
    "sys.path.insert(0, str(repo_root.resolve()))\n",
    "print(\"Added to sys.path:\\\", sys.path[0]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9436fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent_df shape: (24, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pH</th>\n",
       "      <th>turbidity_proxy</th>\n",
       "      <th>predicted_do</th>\n",
       "      <th>predicted_nh3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4342</th>\n",
       "      <td>2025-04-01 11:00:00</td>\n",
       "      <td>28.469006</td>\n",
       "      <td>7.864931</td>\n",
       "      <td>0.281528</td>\n",
       "      <td>4.181165</td>\n",
       "      <td>0.033821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>2025-04-01 11:30:00</td>\n",
       "      <td>27.915065</td>\n",
       "      <td>8.089603</td>\n",
       "      <td>0.554239</td>\n",
       "      <td>4.170613</td>\n",
       "      <td>0.026999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4344</th>\n",
       "      <td>2025-04-01 12:00:00</td>\n",
       "      <td>26.907661</td>\n",
       "      <td>8.264689</td>\n",
       "      <td>0.434256</td>\n",
       "      <td>3.902854</td>\n",
       "      <td>0.011125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp  temperature        pH  turbidity_proxy  \\\n",
       "4342 2025-04-01 11:00:00    28.469006  7.864931         0.281528   \n",
       "4343 2025-04-01 11:30:00    27.915065  8.089603         0.554239   \n",
       "4344 2025-04-01 12:00:00    26.907661  8.264689         0.434256   \n",
       "\n",
       "      predicted_do  predicted_nh3  \n",
       "4342      4.181165       0.033821  \n",
       "4343      4.170613       0.026999  \n",
       "4344      3.902854       0.011125  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step\n",
      "\n",
      "Hybrid forecast output:\n",
      "{'+1h': 0.15413106977939606, '+24h': 0.14396072529619838, '+3d': 0.1447929705835469, '+6h': 0.14368331020041553}\n"
     ]
    }
   ],
   "source": [
    "from src.runtime_forecast import predict_future_risk\n",
    "\n",
    "# Build a test input using the last HISTORY_STEPS rows\n",
    "# from the trusted Montería dataset (df)\n",
    "recent_df = df.sort_values(\"timestamp\").tail(HISTORY_STEPS)[\n",
    "    [\"timestamp\", \"temperature\", \"pH\", \"turbidity_proxy\", \"predicted_do\", \"predicted_nh3\"]\n",
    "].copy()\n",
    "\n",
    "print(\"Recent_df shape:\", recent_df.shape)\n",
    "display(recent_df.tail(3))\n",
    "\n",
    "preds = predict_future_risk(recent_df)\n",
    "print(\"\\nHybrid forecast output:\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f2d6c9",
   "metadata": {},
   "source": [
    "New Cell 17 — Plot deep vs true for a sample horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m df_sorted \u001b[38;5;241m=\u001b[39m sensor_df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# We re-derive the timestamps used for test in the builder, but simpler:\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# If needed we re-run the builder for this horizon to recover t_seq:\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m _, _, (Xte_dummy, yte_dummy) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Instead, let's quickly re-run building to recover timestamps:\u001b[39;00m\n\u001b[0;32m     20\u001b[0m (_, _), (_, _), (_, _,)  \u001b[38;5;66;03m# no-op to remember structure\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# Cell 17 — Visual check: deep vs true for one horizon (e.g. +6h)\n",
    "\n",
    "hname_plot = \"+6h\"  # change to \"+1h\", \"+24h\", \"+3d\" as needed\n",
    "arch_plot  = \"lstm\" # or \"gru\", \"cnn\"\n",
    "\n",
    "if hname_plot in seq_datasets and hname_plot in DEEP_MODELS and arch_plot in DEEP_MODELS[hname_plot]:\n",
    "    ds = seq_datasets[hname_plot]\n",
    "    X_te_seq, y_te_seq = ds[\"test\"]\n",
    "    model = DEEP_MODELS[hname_plot][arch_plot]\n",
    "\n",
    "    y_pred_te = model.predict(X_te_seq).reshape(-1)\n",
    "\n",
    "    # Build a timestamp vector for test sequences (center times)\n",
    "    df_sorted = sensor_df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    # We re-derive the timestamps used for test in the builder, but simpler:\n",
    "    # If needed we re-run the builder for this horizon to recover t_seq:\n",
    "    _, _, (Xte_dummy, yte_dummy) = None, None, None  # placeholder\n",
    "\n",
    "    # Instead, let's quickly re-run building to recover timestamps:\n",
    "    (_, _), (_, _), (_, _,)  # no-op to remember structure\n",
    "else:\n",
    "    print(f\"No deep model {arch_plot} for horizon {hname_plot} or not enough data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29121c92",
   "metadata": {},
   "source": [
    "Cell 12 — Guidance note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d230dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 (classical) forecasting pipeline complete.\n",
      "Use 'model3_forecast_bundle.joblib' + per-horizon models for deployment.\n",
      "Inputs: 5 parameters with lag/rolling features; output: P(HIGH) forecasts for each horizon.\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 3 (classical) forecasting pipeline complete.\")\n",
    "print(\"Use 'model3_forecast_bundle.joblib' + per-horizon models for deployment.\")\n",
    "print(\"Inputs: 5 parameters with lag/rolling features; output: P(HIGH) forecasts for each horizon.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
